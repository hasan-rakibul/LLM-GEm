{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94915d97-0f63-4805-b4a3-66e94b3c5d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "from transformers import (\n",
    "    DataCollatorWithPadding,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from datasets import Dataset\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "os.chdir(\"/g/data/jr19/rh2942/text-empathy/\")\n",
    "from evaluation import pearsonr\n",
    "from utils.utils import plot, get_device, set_all_seeds\n",
    "from utils.common import EarlyStopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf579713-872e-41d6-8a8c-8f14a6e50498",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false' # due to huggingface warning\n",
    "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96ccd8e2-f398-46e3-8c29-b1a6c858c451",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Empathy(nn.Module):\n",
    "    def __init__(self, checkpoint):\n",
    "        super(Empathy, self).__init__()\n",
    "        self.transformer = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=768)\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(768, 512), nn.Tanh(), nn.Dropout(0.2)\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(512+5+1, 256), nn.Tanh(), nn.Dropout(0.2),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        gender=None,\n",
    "        education=None,\n",
    "        race=None,\n",
    "        age=None,\n",
    "        income=None,\n",
    "        distress=None\n",
    "    ):\n",
    "\n",
    "        output = self.transformer(\n",
    "            input_ids= input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "        )\n",
    "\n",
    "        output = self.fc1(output.logits)\n",
    "        output = torch.cat([output, gender, education, race, age, income, distress], 1)\n",
    "        output = self.fc2(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8137d4e-c615-4c54-b5b0-f136f61be132",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distress(nn.Module):\n",
    "    def __init__(self, checkpoint):\n",
    "        super(Distress, self).__init__()\n",
    "        self.transformer = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=768)\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(768, 512), nn.Tanh(), nn.Dropout(0.2)\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(512+5, 256), nn.Tanh(), nn.Dropout(0.2),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        gender=None,\n",
    "        education=None,\n",
    "        race=None,\n",
    "        age=None,\n",
    "        income=None\n",
    "    ):\n",
    "\n",
    "        output = self.transformer(\n",
    "            input_ids= input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "        )\n",
    "\n",
    "        output = self.fc1(output.logits)\n",
    "        output = torch.cat([output, gender, education, race, age, income], 1)\n",
    "        output = self.fc2(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee314462-a714-4cea-80bb-82097bb625c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule:\n",
    "    def __init__(self, task, checkpoint, batch_size, feature_to_tokenise, seed):\n",
    "\n",
    "        self.task = task\n",
    "        self.checkpoint = checkpoint\n",
    "        self.batch_size = batch_size\n",
    "        self.tokeniser = AutoTokenizer.from_pretrained(\n",
    "            self.checkpoint,\n",
    "            use_fast=True\n",
    "        )\n",
    "        self.data_collator = DataCollatorWithPadding(tokenizer=self.tokeniser)\n",
    "        self.feature_to_tokenise = feature_to_tokenise # to tokenise function\n",
    "        self.seed = seed\n",
    "\n",
    "        assert len(self.task) == 2, 'task must be a list with two elements'\n",
    "    \n",
    "    def _process_raw(self, path, send_label):\n",
    "        data = pd.read_csv(path, sep='\\t')\n",
    "    \n",
    "        if send_label:\n",
    "            text = data[self.feature_to_tokenise + self.task]\n",
    "        else:\n",
    "            text = data[self.feature_to_tokenise]\n",
    "\n",
    "        demog = ['gender', 'education', 'race', 'age', 'income']\n",
    "        data_demog = data[demog]\n",
    "        scaler = MinMaxScaler()\n",
    "        data_demog = pd.DataFrame(\n",
    "            scaler.fit_transform(data_demog),\n",
    "            columns=demog\n",
    "        )\n",
    "        data = pd.concat([text, data_demog], axis=1) \n",
    "        return data\n",
    "\n",
    "    def _tokeniser_fn(self, sentence):\n",
    "        if len(self.feature_to_tokenise) == 1: # only one feature\n",
    "            return self.tokeniser(sentence[self.feature_to_tokenise[0]], truncation=True)\n",
    "        # otherwise tokenise a pair of sentence\n",
    "        return self.tokeniser(sentence[self.feature_to_tokenise[0]], sentence[self.feature_to_tokenise[1]], truncation=True)\n",
    "\n",
    "    def _process_input(self, file, send_label):\n",
    "        data = self._process_raw(path=file, send_label=send_label)\n",
    "        data = Dataset.from_pandas(data, preserve_index=False) # convert to huggingface dataset\n",
    "        data = data.map(self._tokeniser_fn, batched=True, remove_columns=self.feature_to_tokenise) # tokenise\n",
    "        data = data.with_format('torch')\n",
    "        return data\n",
    "\n",
    "    # taken from https://pytorch.org/docs/stable/notes/randomness.html\n",
    "    def _seed_worker(self, worker_id):\n",
    "        worker_seed = torch.initial_seed() % 2**32\n",
    "        np.random.seed(worker_seed)\n",
    "        random.seed(worker_seed)     \n",
    "\n",
    "    def dataloader(self, file, send_label, shuffle):\n",
    "        data = self._process_input(file=file, send_label=send_label)\n",
    "\n",
    "        # making sure the shuffling is reproducible\n",
    "        g = torch.Generator()\n",
    "        g.manual_seed(self.seed)\n",
    "        \n",
    "        return DataLoader(\n",
    "            data,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=shuffle,\n",
    "            collate_fn=self.data_collator,\n",
    "            num_workers=24,\n",
    "            worker_init_fn=self._seed_worker,\n",
    "            generator=g\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "095ee97b-ccaf-410a-bd26-5067564e7642",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, task, model_distress, model_empathy, lr, n_epochs_distress, n_epochs_empathy, train_loader,\n",
    "                 dev_loader, dev_label_file, device_id=0):\n",
    "        self.device = get_device(device_id)\n",
    "        self.task = task\n",
    "        self.model_distress = model_distress.to(self.device)\n",
    "        self.model_empathy = model_empathy.to(self.device)\n",
    "        self.lr = lr\n",
    "        self.n_epochs_distress = n_epochs_distress\n",
    "        self.n_epochs_empathy = n_epochs_empathy\n",
    "        self.train_loader = train_loader\n",
    "        self.dev_loader = dev_loader\n",
    "        self.dev_label_file = dev_label_file\n",
    "        \n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.optimiser_distress = torch.optim.AdamW(\n",
    "            params=self.model_distress.parameters(),\n",
    "            lr=self.lr,\n",
    "            betas=(0.9, 0.98),\n",
    "            eps=1e-06,\n",
    "            weight_decay=0.1\n",
    "        )\n",
    "        \n",
    "        self.optimiser_empathy = torch.optim.AdamW(\n",
    "            params=self.model_empathy.parameters(),\n",
    "            lr=self.lr,\n",
    "            betas=(0.9, 0.98),\n",
    "            eps=1e-06,\n",
    "            weight_decay=0.1\n",
    "        )\n",
    "\n",
    "        n_training_step_distress = self.n_epochs_distress*len(self.train_loader)\n",
    "        self.lr_scheduler_distress = get_linear_schedule_with_warmup(\n",
    "            optimizer=self.optimiser_distress,\n",
    "            num_warmup_steps=0.06*n_training_step_distress,\n",
    "            num_training_steps=n_training_step_distress\n",
    "        )\n",
    "        \n",
    "        n_training_step_empathy = self.n_epochs_empathy*len(self.train_loader)\n",
    "        self.lr_scheduler_empathy = get_linear_schedule_with_warmup(\n",
    "            optimizer=self.optimiser_empathy,\n",
    "            num_warmup_steps=0.06*n_training_step_empathy,\n",
    "            num_training_steps=n_training_step_empathy\n",
    "        )\n",
    "        \n",
    "        self.best_pearson_r = -1.0 # initiliasation\n",
    "        self.early_stopper_distress = EarlyStopper(patience=3, min_delta=0.01)\n",
    "        self.early_stopper_empathy = EarlyStopper(patience=3, min_delta=0.01)\n",
    "        \n",
    "        assert len(self.task) == 2, 'task must be a list with two elements'\n",
    "        assert self.task[0] == 'distress', 'First item of task list should be the first guide - distress'\n",
    "    \n",
    "    def _freeze_unfreeze(self, model, freeze=False):\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = not freeze # if freeze is required (True): requires_grad is False\n",
    "            \n",
    "    def _training_step_distress(self):\n",
    "        tr_loss_distress = 0.0\n",
    "        idx = 0\n",
    "        guide = torch.empty((len(self.train_loader.dataset), 1), device=self.device)\n",
    "        \n",
    "        self.model_distress.train()\n",
    "    \n",
    "        for data in self.train_loader:\n",
    "            input_ids = data['input_ids'].to(self.device, dtype=torch.long)\n",
    "            attention_mask = data['attention_mask'].to(self.device, dtype=torch.long)\n",
    "            \n",
    "            distress = data[self.task[0]].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "            \n",
    "            gender = data['gender'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "            education = data['education'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "            race = data['race'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "            age = data['age'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "            income = data['income'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "    \n",
    "            ### Training distress model\n",
    "            self._freeze_unfreeze(model_distress, freeze=False)\n",
    "            self._freeze_unfreeze(model_empathy, freeze=True)\n",
    "            \n",
    "            outputs_distress = self.model_distress(\n",
    "                input_ids=input_ids,                 \n",
    "                attention_mask=attention_mask,\n",
    "                gender=gender,\n",
    "                education=education,\n",
    "                race=race,\n",
    "                age=age,\n",
    "                income=income\n",
    "            )\n",
    "            loss = self.loss_fn(outputs_distress, distress)\n",
    "            tr_loss_distress += loss.item()\n",
    "\n",
    "            self.optimiser_distress.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimiser_distress.step()\n",
    "            self.lr_scheduler_distress.step()\n",
    "\n",
    "            batch_size = outputs_distress.shape[0]\n",
    "            guide[idx:idx+batch_size, :] = outputs_distress\n",
    "            idx += batch_size\n",
    "            \n",
    "        print(f'Train loss (distress): {tr_loss_distress / len(train_loader)}')\n",
    "        return guide.detach()\n",
    "\n",
    "    def _training_step_empathy(self, guide):\n",
    "        tr_loss_empathy = 0.0\n",
    "        idx = 0\n",
    "\n",
    "        self.model_empathy.train()\n",
    "    \n",
    "        for data in self.train_loader:\n",
    "            input_ids = data['input_ids'].to(self.device, dtype=torch.long)\n",
    "            attention_mask = data['attention_mask'].to(self.device, dtype=torch.long)\n",
    "            \n",
    "            empathy = data[self.task[1]].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "            \n",
    "            gender = data['gender'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "            education = data['education'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "            race = data['race'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "            age = data['age'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "            income = data['income'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "\n",
    "            batch_size = empathy.shape[0]\n",
    "            batched_guide = guide[idx:idx+batch_size, :]\n",
    "            idx += batch_size\n",
    "            \n",
    "            ### Training empathy model\n",
    "            self._freeze_unfreeze(model_distress, freeze=True)\n",
    "            self._freeze_unfreeze(model_empathy, freeze=False)\n",
    "            \n",
    "            outputs_empathy = self.model_empathy(\n",
    "                input_ids=input_ids,                 \n",
    "                attention_mask=attention_mask,\n",
    "                gender=gender,\n",
    "                education=education,\n",
    "                race=race,\n",
    "                age=age,\n",
    "                income=income,\n",
    "                distress=batched_guide\n",
    "            )\n",
    "            loss = self.loss_fn(outputs_empathy, empathy)\n",
    "            tr_loss_empathy += loss.item()\n",
    "    \n",
    "            self.optimiser_empathy.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimiser_empathy.step()\n",
    "            self.lr_scheduler_empathy.step()\n",
    "            \n",
    "        print(f'Train loss (empathy): {tr_loss_empathy / len(train_loader)}')\n",
    "\n",
    "    def _fit_distress(self, save_model=False):\n",
    "        print('--- Training distress model ---')\n",
    "        dev_label = pd.read_csv(self.dev_label_file, sep='\\t', header=None)\n",
    "        true_distress = dev_label.iloc[:, 1].tolist()\n",
    "        \n",
    "        for epoch in range(self.n_epochs_distress):\n",
    "            print(f'Epoch: {epoch+1}')\n",
    "            guide = self._training_step_distress()\n",
    "\n",
    "            (preds_distress, _) = self.evaluate(dataloader=self.dev_loader, load_model=False)\n",
    "            \n",
    "            pearson_r_distress = pearsonr(true_distress, preds_distress)\n",
    "            print(f'Pearson r (distress): {pearson_r_distress}')\n",
    "            \n",
    "            val_loss_distress = self.loss_fn(torch.tensor(preds_distress), torch.tensor(true_distress))\n",
    "            print('Validation loss (distress):', val_loss_distress.item())\n",
    "            \n",
    "            if self.early_stopper_distress.early_stop(val_loss_distress):\n",
    "                break\n",
    "\n",
    "            # if (pearson_r_empathy > self.best_pearson_r):\n",
    "            #     self.best_pearson_r = pearson_r_empathy            \n",
    "            #     if save_model:\n",
    "            #         torch.save(self.model.state_dict(), 'EmpathGuRo.pth')\n",
    "            #         print(\"Saved the model in epoch \" + str(epoch+1))\n",
    "            \n",
    "            # print(f'Best dev set Pearson r (empathy): {self.best_pearson_r}\\n')\n",
    "            print()\n",
    "        return guide\n",
    "\n",
    "    def fit_empathy(self, save_model=False):\n",
    "        dev_label = pd.read_csv(self.dev_label_file, sep='\\t', header=None)\n",
    "        true_empathy = dev_label.iloc[:, 0].tolist()\n",
    "        \n",
    "        guide = self._fit_distress()\n",
    "        \n",
    "        print('\\n\\n--- Training empathy model ---')\n",
    "        \n",
    "        for epoch in range(self.n_epochs_empathy):\n",
    "            print(f'Epoch: {epoch+1}')\n",
    "            self._training_step_empathy(guide)\n",
    "\n",
    "            (preds_distress, preds_empathy) = self.evaluate(dataloader=self.dev_loader, load_model=False)\n",
    "            \n",
    "            pearson_r_empathy = pearsonr(true_empathy, preds_empathy)\n",
    "            print(f'Pearson r (empathy): {pearson_r_empathy}')\n",
    "            \n",
    "            val_loss_empathy = self.loss_fn(torch.tensor(preds_empathy), torch.tensor(true_empathy))\n",
    "            print('Validation loss (empathy):', val_loss_empathy.item())\n",
    "            \n",
    "            if self.early_stopper_empathy.early_stop(val_loss_empathy):\n",
    "                break\n",
    "\n",
    "            if (pearson_r_empathy > self.best_pearson_r):\n",
    "                self.best_pearson_r = pearson_r_empathy            \n",
    "                if save_model:\n",
    "                    torch.save(self.model.state_dict(), 'EmpathGuRo.pth')\n",
    "                    print(\"Saved the model in epoch \" + str(epoch+1))\n",
    "            \n",
    "            print(f'Best dev set Pearson r (empathy): {self.best_pearson_r}\\n')\n",
    "\n",
    "    def evaluate(self, dataloader, load_model=False):\n",
    "        if load_model:\n",
    "            self.model.load_state_dict(torch.load('EmpathGuRo.pth'))\n",
    "    \n",
    "        pred_distress = torch.empty((len(dataloader.dataset), 1), device=self.device) # len(self.dev_loader.dataset) --> # of samples\n",
    "        pred_empathy = torch.empty((len(dataloader.dataset), 1), device=self.device) # len(self.dev_loader.dataset) --> # of samples\n",
    "        self.model_distress.eval()\n",
    "        self.model_empathy.eval()\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            idx = 0\n",
    "            for data in dataloader:\n",
    "                input_ids = data['input_ids'].to(self.device, dtype=torch.long)\n",
    "                attention_mask = data['attention_mask'].to(self.device, dtype=torch.long)\n",
    "                gender = data['gender'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "                education = data['education'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "                race = data['race'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "                age = data['age'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "                income = data['income'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "                # self.prev_empathy = self.prev_empathy.to(self.device, dtype=torch.float).view(-1, 1)\n",
    "        \n",
    "                outputs_distress = self.model_distress(\n",
    "                    input_ids=input_ids,                 \n",
    "                    attention_mask=attention_mask,\n",
    "                    gender=gender,\n",
    "                    education=education,\n",
    "                    race=race,\n",
    "                    age=age,\n",
    "                    income=income\n",
    "                )\n",
    "                \n",
    "                batch_size = outputs_distress.shape[0]\n",
    "                pred_distress[idx:idx+batch_size, :] = outputs_distress\n",
    "                \n",
    "                outputs_empathy = self.model_empathy(\n",
    "                    input_ids=input_ids,                 \n",
    "                    attention_mask=attention_mask,\n",
    "                    gender=gender,\n",
    "                    education=education,\n",
    "                    race=race,\n",
    "                    age=age,\n",
    "                    income=income,\n",
    "                    distress=outputs_distress\n",
    "                )\n",
    "        \n",
    "                pred_empathy[idx:idx+batch_size, :] = outputs_empathy\n",
    "                \n",
    "                idx += batch_size\n",
    "            \n",
    "        return ([float(k) for k in pred_distress], [float(k) for k in pred_empathy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "80e65bb5-f377-4664-8720-b18276ee77b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 'roberta-base'\n",
    "task = ['distress', 'empathy'] #guide first\n",
    "# feature_to_tokenise=['demographic_essay', 'article']\n",
    "# feature_to_tokenise=['demographic', 'essay']\n",
    "feature_to_tokenise=['demographic_essay']\n",
    "seed = 0\n",
    "\n",
    "# train_file = './data/essay-train-ws22-ws23.tsv'\n",
    "train_file = './data/PREPROCESSED-WS22-WS23-train.tsv'\n",
    "# train_file = './data/COMBINED-PREPROCESSED-PARAPHRASED-WS22-WS23-train.tsv'\n",
    "\n",
    "# WASSA 2022\n",
    "# dev_file = './data/PREPROCESSED-WS22-dev.tsv'\n",
    "# dev_label_file = './data/WASSA22/goldstandard_dev_2022.tsv'\n",
    "# test_file = './data/PREPROCESSED-WS22-test.tsv'\n",
    "\n",
    "# WASSA 2023\n",
    "dev_file = './data/PREPROCESSED-WS23-dev.tsv'\n",
    "dev_label_file = './data/WASSA23/goldstandard_dev.tsv'\n",
    "test_file = './data/PREPROCESSED-WS23-test.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc69ec6b-9bda-44f5-90b4-d02754f65d41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2636 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/208 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training distress model ---\n",
      "Epoch: 1\n",
      "Train loss (distress): 9.668442368507385\n",
      "Pearson r (distress): 0.068\n",
      "Validation loss (distress): 3.095682382583618\n",
      "\n",
      "Epoch: 2\n",
      "Train loss (distress): 3.7979113867788605\n",
      "Pearson r (distress): 0.289\n",
      "Validation loss (distress): 3.021509885787964\n",
      "\n",
      "Epoch: 3\n",
      "Train loss (distress): 3.327391808683222\n",
      "Pearson r (distress): 0.391\n",
      "Validation loss (distress): 2.8054873943328857\n",
      "\n",
      "Epoch: 4\n",
      "Train loss (distress): 2.7452551621379273\n",
      "Pearson r (distress): 0.459\n",
      "Validation loss (distress): 2.6769156455993652\n",
      "\n",
      "Epoch: 5\n",
      "Train loss (distress): 2.219888780333779\n",
      "Pearson r (distress): 0.499\n",
      "Validation loss (distress): 2.472139835357666\n",
      "\n",
      "Epoch: 6\n",
      "Train loss (distress): 1.8720871527989706\n",
      "Pearson r (distress): 0.514\n",
      "Validation loss (distress): 2.7824440002441406\n",
      "\n",
      "Epoch: 7\n",
      "Train loss (distress): 1.5658171830755292\n",
      "Pearson r (distress): 0.516\n",
      "Validation loss (distress): 2.6947550773620605\n",
      "\n",
      "Epoch: 8\n",
      "Train loss (distress): 1.3129501481850943\n",
      "Pearson r (distress): 0.494\n",
      "Validation loss (distress): 3.065455436706543\n",
      "\n",
      "\n",
      "--- Training empathy model ---\n",
      "Epoch: 1\n",
      "Train loss (empathy): 12.56967641512553\n",
      "Pearson r (empathy): -0.016\n",
      "Validation loss (empathy): 4.084070205688477\n",
      "Best dev set Pearson r (empathy): -0.016\n",
      "\n",
      "Epoch: 2\n",
      "Train loss (empathy): 3.672875420252482\n",
      "Pearson r (empathy): 0.276\n",
      "Validation loss (empathy): 2.783940553665161\n",
      "Best dev set Pearson r (empathy): 0.276\n",
      "\n",
      "Epoch: 3\n",
      "Train loss (empathy): 3.3885399160963114\n",
      "Pearson r (empathy): 0.277\n",
      "Validation loss (empathy): 2.59777569770813\n",
      "Best dev set Pearson r (empathy): 0.277\n",
      "\n",
      "Epoch: 4\n",
      "Train loss (empathy): 2.715845870249199\n",
      "Pearson r (empathy): 0.512\n",
      "Validation loss (empathy): 2.526057004928589\n",
      "Best dev set Pearson r (empathy): 0.512\n",
      "\n",
      "Epoch: 5\n",
      "Train loss (empathy): 2.2081172412092034\n",
      "Pearson r (empathy): 0.51\n",
      "Validation loss (empathy): 2.093794345855713\n",
      "Best dev set Pearson r (empathy): 0.512\n",
      "\n",
      "Epoch: 6\n",
      "Train loss (empathy): 1.8058728109706532\n",
      "Pearson r (empathy): 0.453\n",
      "Validation loss (empathy): 4.09576416015625\n",
      "Best dev set Pearson r (empathy): 0.512\n",
      "\n",
      "Epoch: 7\n",
      "Train loss (empathy): 1.4652055595860336\n",
      "Pearson r (empathy): 0.492\n",
      "Validation loss (empathy): 2.413668394088745\n",
      "Best dev set Pearson r (empathy): 0.512\n",
      "\n",
      "Epoch: 8\n",
      "Train loss (empathy): 1.2039253014506717\n",
      "Pearson r (empathy): 0.477\n",
      "Validation loss (empathy): 2.816072702407837\n"
     ]
    }
   ],
   "source": [
    "set_all_seeds(seed)\n",
    "\n",
    "data_module = DataModule(\n",
    "    task=task,\n",
    "    checkpoint=checkpoint,\n",
    "    batch_size=16,\n",
    "    feature_to_tokenise=feature_to_tokenise,\n",
    "    seed=0\n",
    ")\n",
    "\n",
    "train_loader = data_module.dataloader(file=train_file, send_label=True, shuffle=True)\n",
    "dev_loader = data_module.dataloader(file=dev_file, send_label=False, shuffle=False)\n",
    "test_loader = data_module.dataloader(file=test_file, send_label=False, shuffle=False)\n",
    "\n",
    "model_distress = Distress(checkpoint=checkpoint)\n",
    "model_empathy = Empathy(checkpoint=checkpoint)\n",
    "\n",
    "trainer = Trainer(\n",
    "    task=task,\n",
    "    model_distress=model_distress,\n",
    "    model_empathy=model_empathy,\n",
    "    lr=1e-5,\n",
    "    n_epochs_distress=10,\n",
    "    n_epochs_empathy=20,\n",
    "    train_loader=train_loader,\n",
    "    dev_loader=dev_loader,\n",
    "    dev_label_file=dev_label_file,\n",
    "    device_id=0\n",
    ")\n",
    "\n",
    "trainer.fit_empathy(save_model=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab15c9c9-d937-4f8a-825f-7ef384dad0f3",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "78d5d6d3-b64d-4ffa-80bb-e20306380e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emp</th>\n",
       "      <th>dis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.240249</td>\n",
       "      <td>5.240249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.962897</td>\n",
       "      <td>4.962897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.524402</td>\n",
       "      <td>5.524402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.303425</td>\n",
       "      <td>5.303425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.142904</td>\n",
       "      <td>5.142904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4.535624</td>\n",
       "      <td>4.535624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4.815518</td>\n",
       "      <td>4.815518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3.978409</td>\n",
       "      <td>3.978409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5.163967</td>\n",
       "      <td>5.163967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>3.133869</td>\n",
       "      <td>3.133869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         emp       dis\n",
       "0   5.240249  5.240249\n",
       "1   4.962897  4.962897\n",
       "2   5.524402  5.524402\n",
       "3   5.303425  5.303425\n",
       "4   5.142904  5.142904\n",
       "..       ...       ...\n",
       "95  4.535624  4.535624\n",
       "96  4.815518  4.815518\n",
       "97  3.978409  3.978409\n",
       "98  5.163967  5.163967\n",
       "99  3.133869  3.133869\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = trainer.evaluate(dataloader=test_loader, load_model=True)\n",
    "pred_df = pd.DataFrame({'emp': pred, 'dis': pred}) # we're not predicting distress, just aligning with submission system\n",
    "pred_df.to_csv('./tmp/predictions_EMP.tsv', sep='\\t', index=None, header=None)\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999c566c-886e-4366-bbac-e48c60d36302",
   "metadata": {},
   "source": [
    "# Extra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0951f2a-0bbf-47c1-9301-5735230580db",
   "metadata": {},
   "source": [
    "## Batch-level training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fadc9d-6d94-4c58-9b08-03475438a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, task, model_distress, model_empathy, lr, n_epochs, train_loader,\n",
    "                 dev_loader, dev_label_file, device_id=0):\n",
    "        self.device = get_device(device_id)\n",
    "        self.task = task\n",
    "        self.model_distress = model_distress.to(self.device)\n",
    "        self.model_empathy = model_empathy.to(self.device)\n",
    "        self.lr = lr\n",
    "        self.n_epochs = n_epochs\n",
    "        self.train_loader = train_loader\n",
    "        self.dev_loader = dev_loader\n",
    "        self.dev_label_file = dev_label_file\n",
    "        \n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.optimiser_distress = torch.optim.AdamW(\n",
    "            params=self.model_distress.parameters(),\n",
    "            lr=self.lr,\n",
    "            betas=(0.9, 0.98),\n",
    "            eps=1e-06,\n",
    "            weight_decay=0.1\n",
    "        )\n",
    "        \n",
    "        self.optimiser_empathy = torch.optim.AdamW(\n",
    "            params=self.model_empathy.parameters(),\n",
    "            lr=self.lr,\n",
    "            betas=(0.9, 0.98),\n",
    "            eps=1e-06,\n",
    "            weight_decay=0.1\n",
    "        )\n",
    "\n",
    "        n_training_step = self.n_epochs*len(self.train_loader)\n",
    "        \n",
    "        self.lr_scheduler_distress = get_linear_schedule_with_warmup(\n",
    "            optimizer=self.optimiser_distress,\n",
    "            num_warmup_steps=0.06*n_training_step,\n",
    "            num_training_steps=n_training_step\n",
    "        )\n",
    "        \n",
    "        self.lr_scheduler_empathy = get_linear_schedule_with_warmup(\n",
    "            optimizer=self.optimiser_empathy,\n",
    "            num_warmup_steps=0.06*n_training_step,\n",
    "            num_training_steps=n_training_step\n",
    "        )\n",
    "        \n",
    "        self.best_pearson_r = -1.0 # initiliasation\n",
    "        self.early_stopper = EarlyStopper(patience=3, min_delta=0.01)\n",
    "        # self.prev_empathy = torch.rand(dev_loader.batch_size, 1) * 6 + 1 # random initialisation between 1.0 to 7.0\n",
    "        \n",
    "        assert len(self.task) == 2, 'task must be a list with two elements'\n",
    "        assert self.task[0] == 'distress', 'First item of task list should be the first guide - distress'\n",
    "    \n",
    "    def _freeze_unfreeze(self, model, freeze=False):\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = not freeze # if freeze is required (True): requires_grad is False\n",
    "            \n",
    "    def _training_step(self):\n",
    "        tr_loss_distress = 0.0\n",
    "        tr_loss_empathy = 0.0\n",
    "        \n",
    "        self.model_distress.train()\n",
    "        self.model_empathy.train()\n",
    "    \n",
    "        for data in self.train_loader:\n",
    "            input_ids = data['input_ids'].to(self.device, dtype=torch.long)\n",
    "            attention_mask = data['attention_mask'].to(self.device, dtype=torch.long)\n",
    "            \n",
    "            distress = data[self.task[0]].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "            empathy = data[self.task[1]].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "            \n",
    "            gender = data['gender'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "            education = data['education'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "            race = data['race'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "            age = data['age'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "            income = data['income'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "    \n",
    "            ### Training distress model\n",
    "            self._freeze_unfreeze(model_distress, freeze=False)\n",
    "            self._freeze_unfreeze(model_empathy, freeze=True)\n",
    "            \n",
    "            outputs_distress = self.model_distress(\n",
    "                input_ids=input_ids,                 \n",
    "                attention_mask=attention_mask,\n",
    "                gender=gender,\n",
    "                education=education,\n",
    "                race=race,\n",
    "                age=age,\n",
    "                income=income,\n",
    "                # empathy=empathy\n",
    "            )\n",
    "            loss = self.loss_fn(outputs_distress, distress)\n",
    "            tr_loss_distress += loss.item()\n",
    "\n",
    "            self.optimiser_distress.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimiser_distress.step()\n",
    "            self.lr_scheduler_distress.step()\n",
    "            \n",
    "            ### Training empathy model\n",
    "            self._freeze_unfreeze(model_distress, freeze=True)\n",
    "            self._freeze_unfreeze(model_empathy, freeze=False)\n",
    "            \n",
    "            outputs_empathy = self.model_empathy(\n",
    "                input_ids=input_ids,                 \n",
    "                attention_mask=attention_mask,\n",
    "                gender=gender,\n",
    "                education=education,\n",
    "                race=race,\n",
    "                age=age,\n",
    "                income=income,\n",
    "                distress=outputs_distress.detach()\n",
    "            )\n",
    "            loss = self.loss_fn(outputs_empathy, empathy)\n",
    "            tr_loss_empathy += loss.item()\n",
    "    \n",
    "            self.optimiser_empathy.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimiser_empathy.step()\n",
    "            self.lr_scheduler_empathy.step()\n",
    "            \n",
    "        print(f'Train loss (distress): {tr_loss_distress / len(train_loader)}')\n",
    "        print(f'Train loss (empathy): {tr_loss_empathy / len(train_loader)}')\n",
    "\n",
    "    def fit(self, save_model=False):\n",
    "        dev_label = pd.read_csv(self.dev_label_file, sep='\\t', header=None)\n",
    "        true_distress = dev_label.iloc[:, 1].tolist()\n",
    "        true_empathy = dev_label.iloc[:, 0].tolist()\n",
    "        \n",
    "        for epoch in range(self.n_epochs):\n",
    "            print(f'Epoch: {epoch+1}')\n",
    "            self._training_step()\n",
    "\n",
    "            (preds_distress, preds_empathy) = self.evaluate(dataloader=self.dev_loader, load_model=False)\n",
    "\n",
    "            pearson_r_distress = pearsonr(true_distress, preds_distress)\n",
    "            print(f'Pearson r (distress): {pearson_r_distress}')\n",
    "            \n",
    "            pearson_r_empathy = pearsonr(true_empathy, preds_empathy)\n",
    "            print(f'Pearson r (empathy): {pearson_r_empathy}')\n",
    "            \n",
    "            val_loss_empathy = self.loss_fn(torch.tensor(preds_empathy), torch.tensor(true_empathy))\n",
    "            print('Validation loss (empathy):', val_loss_empathy.item())\n",
    "            \n",
    "            if self.early_stopper.early_stop(val_loss_empathy):\n",
    "                break\n",
    "\n",
    "            if (pearson_r_empathy > self.best_pearson_r):\n",
    "                self.best_pearson_r = pearson_r_empathy            \n",
    "                if save_model:\n",
    "                    torch.save(self.model.state_dict(), 'EmpathGuRo.pth')\n",
    "                    print(\"Saved the model in epoch \" + str(epoch+1))\n",
    "            \n",
    "            print(f'Best dev set Pearson r (empathy): {self.best_pearson_r}\\n')\n",
    "\n",
    "    def evaluate(self, dataloader, load_model=False):\n",
    "        if load_model:\n",
    "            self.model.load_state_dict(torch.load('EmpathGuRo.pth'))\n",
    "    \n",
    "        pred_distress = torch.empty((len(dataloader.dataset), 1), device=self.device) # len(self.dev_loader.dataset) --> # of samples\n",
    "        pred_empathy = torch.empty((len(dataloader.dataset), 1), device=self.device) # len(self.dev_loader.dataset) --> # of samples\n",
    "        self.model_distress.eval()\n",
    "        self.model_empathy.eval()\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            idx = 0\n",
    "            for data in dataloader:\n",
    "                input_ids = data['input_ids'].to(self.device, dtype=torch.long)\n",
    "                attention_mask = data['attention_mask'].to(self.device, dtype=torch.long)\n",
    "                gender = data['gender'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "                education = data['education'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "                race = data['race'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "                age = data['age'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "                income = data['income'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "                # self.prev_empathy = self.prev_empathy.to(self.device, dtype=torch.float).view(-1, 1)\n",
    "        \n",
    "                outputs_distress = self.model_distress(\n",
    "                    input_ids=input_ids,                 \n",
    "                    attention_mask=attention_mask,\n",
    "                    gender=gender,\n",
    "                    education=education,\n",
    "                    race=race,\n",
    "                    age=age,\n",
    "                    income=income,\n",
    "                    # empathy=self.prev_empathy\n",
    "                )\n",
    "                \n",
    "                batch_size = outputs_distress.shape[0]\n",
    "                pred_distress[idx:idx+batch_size, :] = outputs_distress\n",
    "                \n",
    "                outputs_empathy = self.model_empathy(\n",
    "                    input_ids=input_ids,                 \n",
    "                    attention_mask=attention_mask,\n",
    "                    gender=gender,\n",
    "                    education=education,\n",
    "                    race=race,\n",
    "                    age=age,\n",
    "                    income=income,\n",
    "                    distress=outputs_distress\n",
    "                )\n",
    "        \n",
    "                pred_empathy[idx:idx+batch_size, :] = outputs_empathy\n",
    "                \n",
    "                # self.prev_empathy = outputs_empathy\n",
    "                \n",
    "                idx += batch_size\n",
    "            \n",
    "        return ([float(k) for k in pred_distress], [float(k) for k in pred_empathy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6975488e-e76f-4728-8f90-474f34732c44",
   "metadata": {},
   "source": [
    "## Epoch-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd0197b7-e963-4feb-b81f-5f5e7201c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, task, model_distress, model_empathy, lr, n_epochs, train_loader,\n",
    "                 dev_loader, dev_label_file, device_id=0):\n",
    "        self.device = get_device(device_id)\n",
    "        self.task = task\n",
    "        self.model_distress = model_distress.to(self.device)\n",
    "        self.model_empathy = model_empathy.to(self.device)\n",
    "        self.lr = lr\n",
    "        self.n_epochs = n_epochs\n",
    "        self.train_loader = train_loader\n",
    "        self.dev_loader = dev_loader\n",
    "        self.dev_label_file = dev_label_file\n",
    "        \n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.optimiser_distress = torch.optim.AdamW(\n",
    "            params=self.model_distress.parameters(),\n",
    "            lr=self.lr,\n",
    "            betas=(0.9, 0.98),\n",
    "            eps=1e-06,\n",
    "            weight_decay=0.1\n",
    "        )\n",
    "        \n",
    "        self.optimiser_empathy = torch.optim.AdamW(\n",
    "            params=self.model_empathy.parameters(),\n",
    "            lr=self.lr,\n",
    "            betas=(0.9, 0.98),\n",
    "            eps=1e-06,\n",
    "            weight_decay=0.1\n",
    "        )\n",
    "\n",
    "        n_training_step = self.n_epochs*len(self.train_loader)\n",
    "        \n",
    "        self.lr_scheduler_distress = get_linear_schedule_with_warmup(\n",
    "            optimizer=self.optimiser_distress,\n",
    "            num_warmup_steps=0.06*n_training_step,\n",
    "            num_training_steps=n_training_step\n",
    "        )\n",
    "        \n",
    "        self.lr_scheduler_empathy = get_linear_schedule_with_warmup(\n",
    "            optimizer=self.optimiser_empathy,\n",
    "            num_warmup_steps=0.06*n_training_step,\n",
    "            num_training_steps=n_training_step\n",
    "        )\n",
    "        \n",
    "        self.best_pearson_r = -1.0 # initiliasation\n",
    "        self.early_stopper = EarlyStopper(patience=3, min_delta=0.01)\n",
    "        \n",
    "        assert len(self.task) == 2, 'task must be a list with two elements'\n",
    "        assert self.task[0] == 'distress', 'First item of task list should be the first guide - distress'\n",
    "    \n",
    "    def _freeze_unfreeze(self, model, freeze=False):\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = not freeze # if freeze is required (True): requires_grad is False\n",
    "            \n",
    "    def _training_step_distress(self):\n",
    "        tr_loss_distress = 0.0\n",
    "        idx = 0\n",
    "        guide = torch.empty((len(self.train_loader.dataset), 1), device=self.device)\n",
    "        \n",
    "        self.model_distress.train()\n",
    "    \n",
    "        for data in self.train_loader:\n",
    "            input_ids = data['input_ids'].to(self.device, dtype=torch.long)\n",
    "            attention_mask = data['attention_mask'].to(self.device, dtype=torch.long)\n",
    "            \n",
    "            distress = data[self.task[0]].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "            \n",
    "            gender = data['gender'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "            education = data['education'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "            race = data['race'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "            age = data['age'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "            income = data['income'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "    \n",
    "            ### Training distress model\n",
    "            self._freeze_unfreeze(model_distress, freeze=False)\n",
    "            self._freeze_unfreeze(model_empathy, freeze=True)\n",
    "            \n",
    "            outputs_distress = self.model_distress(\n",
    "                input_ids=input_ids,                 \n",
    "                attention_mask=attention_mask,\n",
    "                gender=gender,\n",
    "                education=education,\n",
    "                race=race,\n",
    "                age=age,\n",
    "                income=income\n",
    "            )\n",
    "            loss = self.loss_fn(outputs_distress, distress)\n",
    "            tr_loss_distress += loss.item()\n",
    "\n",
    "            self.optimiser_distress.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimiser_distress.step()\n",
    "            self.lr_scheduler_distress.step()\n",
    "\n",
    "            batch_size = outputs_distress.shape[0]\n",
    "            guide[idx:idx+batch_size, :] = outputs_distress\n",
    "            idx += batch_size\n",
    "            \n",
    "        print(f'Train loss (distress): {tr_loss_distress / len(train_loader)}')\n",
    "        return guide.detach()\n",
    "\n",
    "    def _training_step_empathy(self, guide):\n",
    "        tr_loss_empathy = 0.0\n",
    "        idx = 0\n",
    "\n",
    "        self.model_empathy.train()\n",
    "    \n",
    "        for data in self.train_loader:\n",
    "            input_ids = data['input_ids'].to(self.device, dtype=torch.long)\n",
    "            attention_mask = data['attention_mask'].to(self.device, dtype=torch.long)\n",
    "            \n",
    "            empathy = data[self.task[1]].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "            \n",
    "            gender = data['gender'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "            education = data['education'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "            race = data['race'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "            age = data['age'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "            income = data['income'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "\n",
    "            batch_size = empathy.shape[0]\n",
    "            batched_guide = guide[idx:idx+batch_size, :]\n",
    "            idx += batch_size\n",
    "            \n",
    "            ### Training empathy model\n",
    "            self._freeze_unfreeze(model_distress, freeze=True)\n",
    "            self._freeze_unfreeze(model_empathy, freeze=False)\n",
    "            \n",
    "            outputs_empathy = self.model_empathy(\n",
    "                input_ids=input_ids,                 \n",
    "                attention_mask=attention_mask,\n",
    "                gender=gender,\n",
    "                education=education,\n",
    "                race=race,\n",
    "                age=age,\n",
    "                income=income,\n",
    "                distress=batched_guide\n",
    "            )\n",
    "            loss = self.loss_fn(outputs_empathy, empathy)\n",
    "            tr_loss_empathy += loss.item()\n",
    "    \n",
    "            self.optimiser_empathy.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimiser_empathy.step()\n",
    "            self.lr_scheduler_empathy.step()\n",
    "            \n",
    "        print(f'Train loss (empathy): {tr_loss_empathy / len(train_loader)}')\n",
    "\n",
    "    def fit(self, save_model=False):\n",
    "        dev_label = pd.read_csv(self.dev_label_file, sep='\\t', header=None)\n",
    "        true_distress = dev_label.iloc[:, 1].tolist()\n",
    "        true_empathy = dev_label.iloc[:, 0].tolist()\n",
    "        \n",
    "        for epoch in range(self.n_epochs):\n",
    "            print(f'Epoch: {epoch+1}')\n",
    "            guide = self._training_step_distress()\n",
    "            self._training_step_empathy(guide)\n",
    "\n",
    "            (preds_distress, preds_empathy) = self.evaluate(dataloader=self.dev_loader, load_model=False)\n",
    "\n",
    "            pearson_r_distress = pearsonr(true_distress, preds_distress)\n",
    "            print(f'Pearson r (distress): {pearson_r_distress}')\n",
    "            \n",
    "            pearson_r_empathy = pearsonr(true_empathy, preds_empathy)\n",
    "            print(f'Pearson r (empathy): {pearson_r_empathy}')\n",
    "            \n",
    "            val_loss_empathy = self.loss_fn(torch.tensor(preds_empathy), torch.tensor(true_empathy))\n",
    "            print('Validation loss (empathy):', val_loss_empathy.item())\n",
    "            \n",
    "            if self.early_stopper.early_stop(val_loss_empathy):\n",
    "                break\n",
    "\n",
    "            if (pearson_r_empathy > self.best_pearson_r):\n",
    "                self.best_pearson_r = pearson_r_empathy            \n",
    "                if save_model:\n",
    "                    torch.save(self.model.state_dict(), 'EmpathGuRo.pth')\n",
    "                    print(\"Saved the model in epoch \" + str(epoch+1))\n",
    "            \n",
    "            print(f'Best dev set Pearson r (empathy): {self.best_pearson_r}\\n')\n",
    "\n",
    "    def evaluate(self, dataloader, load_model=False):\n",
    "        if load_model:\n",
    "            self.model.load_state_dict(torch.load('EmpathGuRo.pth'))\n",
    "    \n",
    "        pred_distress = torch.empty((len(dataloader.dataset), 1), device=self.device) # len(self.dev_loader.dataset) --> # of samples\n",
    "        pred_empathy = torch.empty((len(dataloader.dataset), 1), device=self.device) # len(self.dev_loader.dataset) --> # of samples\n",
    "        self.model_distress.eval()\n",
    "        self.model_empathy.eval()\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            idx = 0\n",
    "            for data in dataloader:\n",
    "                input_ids = data['input_ids'].to(self.device, dtype=torch.long)\n",
    "                attention_mask = data['attention_mask'].to(self.device, dtype=torch.long)\n",
    "                gender = data['gender'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "                education = data['education'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "                race = data['race'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "                age = data['age'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "                income = data['income'].to(self.device, dtype=torch.float).view(-1, 1)\n",
    "                # self.prev_empathy = self.prev_empathy.to(self.device, dtype=torch.float).view(-1, 1)\n",
    "        \n",
    "                outputs_distress = self.model_distress(\n",
    "                    input_ids=input_ids,                 \n",
    "                    attention_mask=attention_mask,\n",
    "                    gender=gender,\n",
    "                    education=education,\n",
    "                    race=race,\n",
    "                    age=age,\n",
    "                    income=income,\n",
    "                    # empathy=self.prev_empathy\n",
    "                )\n",
    "                \n",
    "                batch_size = outputs_distress.shape[0]\n",
    "                pred_distress[idx:idx+batch_size, :] = outputs_distress\n",
    "                \n",
    "                outputs_empathy = self.model_empathy(\n",
    "                    input_ids=input_ids,                 \n",
    "                    attention_mask=attention_mask,\n",
    "                    gender=gender,\n",
    "                    education=education,\n",
    "                    race=race,\n",
    "                    age=age,\n",
    "                    income=income,\n",
    "                    distress=outputs_distress\n",
    "                )\n",
    "        \n",
    "                pred_empathy[idx:idx+batch_size, :] = outputs_empathy\n",
    "                \n",
    "                # self.prev_empathy = outputs_empathy\n",
    "                \n",
    "                idx += batch_size\n",
    "            \n",
    "        return ([float(k) for k in pred_distress], [float(k) for k in pred_empathy])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
