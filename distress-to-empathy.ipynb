{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "117e11a2-7ae0-4783-b041-c20a79135cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    DataCollatorWithPadding,\n",
    "    get_scheduler\n",
    ")\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c84076e2-133f-4f2b-b6aa-73e8b3e223f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/g/data/jr19/rh2942/text-empathy/\")\n",
    "from evaluation import pearsonr\n",
    "from utils.plot import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a446ce0-5ec2-4fd9-8dce-9b6dc4254d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device(device_id=0):\n",
    "    return torch.device(\"cuda\", device_id) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "def set_all_seeds(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de7185a9-f080-45ae-9ea8-14a6ff9cd2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['empathy', 'distress']\n",
    "\n",
    "checkpoint = \"microsoft/deberta-v3-base\"\n",
    "\n",
    "train_file = \"./data/PREPROCESSED-essay-train.csv\"\n",
    "dev_file = \"./data/PREPROCESSED-essay-dev.csv\"\n",
    "train_dev_file = \"./data/PREPROCESSED-essay-train-dev.csv\"\n",
    "test_file = \"./data/PREPROCESSED-test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5374953b-1e22-4554-b3fc-3464e89ed403",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['demographic_essay', 'article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7bbd726-5c16-4f14-8102-e532649f7707",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokeniser = AutoTokenizer.from_pretrained(checkpoint, use_fast=False) # fast tokeniser showed warning that it may return incorrect tokens\n",
    "\n",
    "# data collator due to variable max token length per batch size\n",
    "data_collator = DataCollatorWithPadding(tokenizer = tokeniser)\n",
    "\n",
    "def load_tokenised_data(filename, tasks, feature_to_tokenise, train, batch_size, shuffle):\n",
    "    #padding=\"longest\" can be deferred to do dynamic padding\n",
    "    def tokenise_fn(sentence):\n",
    "        return tokeniser(sentence[feature_to_tokenise[0]], sentence[feature_to_tokenise[1]], truncation=True, max_length=512)\n",
    "   \n",
    "    input_data = pd.read_csv(filename, header=0, index_col=0)\n",
    "    \n",
    "    if train:\n",
    "        chosen_data = input_data[feature_to_tokenise + tasks]\n",
    "    else:\n",
    "        chosen_data = input_data[feature_to_tokenise]  #test data shouldn't have output label\n",
    "\n",
    "    hugging_dataset = Dataset.from_pandas(chosen_data, preserve_index=False)\n",
    "\n",
    "    tokenised_hugging_dataset = hugging_dataset.map(tokenise_fn, batched=True, remove_columns = feature_to_tokenise)\n",
    "    \n",
    "    tokenised_hugging_dataset = tokenised_hugging_dataset.with_format(\"torch\")\n",
    "    \n",
    "    torchloader = torch.utils.data.DataLoader(\n",
    "        tokenised_hugging_dataset, shuffle=shuffle, batch_size=batch_size, collate_fn=data_collator\n",
    "    )\n",
    "\n",
    "    return torchloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aef2a409-5614-42ab-80f9-8a93383a152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(tasks, features, batch_size):\n",
    "    \"\"\"\n",
    "    feature: list of features to tokenise\n",
    "    \"\"\"\n",
    "    \n",
    "    trainloader = load_tokenised_data(\n",
    "        filename=train_file, tasks=tasks, feature_to_tokenise=features, train=True, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "        # devloader in train mode to pass labels\n",
    "    devloader = load_tokenised_data(\n",
    "        filename=dev_file, tasks=tasks, feature_to_tokenise=features, train=True, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    return trainloader, devloader\n",
    "\n",
    "def get_test_data(tasks, features, batch_size):\n",
    "    \"\"\"\n",
    "    feature: list of features to tokenise\n",
    "    \"\"\"\n",
    "    \n",
    "    testloader = load_tokenised_data(\n",
    "        filename=test_file, tasks=tasks, feature_to_tokenise=features, train=False, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    return testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03a9154f-7986-4538-b95b-ae89fe4054a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGuidedTransformer(nn.Module):\n",
    "    def __init__(self, checkpoint=\"microsoft/deberta-v3-base\", n_freeze=-1, task=tasks[0]):\n",
    "        super(RecurrentGuidedTransformer, self).__init__()\n",
    "\n",
    "        self.task = task\n",
    "        self.transformer_last_hidden_size = 768\n",
    "        \n",
    "        self.transformer = AutoModelForSequenceClassification.from_pretrained(\n",
    "            checkpoint,\n",
    "            config = AutoConfig.from_pretrained(\n",
    "                checkpoint,\n",
    "                output_attentions=True,\n",
    "                output_hidden_states=True,\n",
    "                num_labels=self.transformer_last_hidden_size\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.transformer_2 = AutoModelForSequenceClassification.from_pretrained(\n",
    "            checkpoint,\n",
    "            config = AutoConfig.from_pretrained(\n",
    "                checkpoint,\n",
    "                output_attentions=True,\n",
    "                output_hidden_states=True,\n",
    "                num_labels=self.transformer_last_hidden_size\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # New layers\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "        # 1st stream\n",
    "        self.fc1_1 = nn.Linear(self.transformer_last_hidden_size, 256)\n",
    "        \n",
    "        self.fc1_2 = nn.Linear(256, 1) # predicting distress\n",
    "\n",
    "        # 2nd stream\n",
    "        self.fc2_1 = nn.Linear(769, 256) # input: last hidden state + distress\n",
    "\n",
    "        self.fc_final = nn.Linear(256, 1) # regression problem\n",
    "        \n",
    "\n",
    "        # Freezing layers\n",
    "        if n_freeze:\n",
    "            print(f\"Freezed layers: {n_freeze}\")\n",
    "            # freeze the embedding layer when n_freeze = -1)\n",
    "            for param in self.transformer.deberta.embeddings.parameters():\n",
    "                param.requires_grad = False\n",
    "    \n",
    "            # freeze other layers as per n_freeze\n",
    "            if n_freeze != -1:\n",
    "                for layer in self.transformer.deberta.encoder.layer[:n_freeze]:\n",
    "                    for param in layer.parameters():\n",
    "                        param.requires_grad = False\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        empathy=None,\n",
    "        distress=None\n",
    "    ):\n",
    "        \n",
    "        outputs = self.transformer(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask = attention_mask,\n",
    "            token_type_ids = token_type_ids\n",
    "        )\n",
    "        # print(outputs.keys())\n",
    "        # will return ['logits', 'hidden_states', 'attentions']\n",
    "\n",
    "        x = self.dropout(outputs.logits) # output.logits aka pooled output from [CLS] token beacuse of AutoModelForSequenceClassification\n",
    "        x = F.tanh(self.fc1_1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1_2(x) # distress output\n",
    "\n",
    "        # starting 2nd stream\n",
    "        outputs = self.transformer(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask = attention_mask,\n",
    "            token_type_ids = token_type_ids\n",
    "        )\n",
    "\n",
    "        x_2 = self.dropout(outputs.logits) # output.logits aka pooled output from [CLS] token beacuse of AutoModelForSequenceClassification\n",
    "        x_2 = torch.cat((x_2, x), dim=1)\n",
    "\n",
    "        x_2 = F.tanh(self.fc2_1(x_2))\n",
    "        x_2 = self.dropout(x_2)\n",
    "        x_2 = self.fc_final(x_2) # distress output     \n",
    "\n",
    "        if self.task == tasks[0]: # empathy\n",
    "            loss_distress = None\n",
    "            if distress is not None:\n",
    "                loss_distress = F.mse_loss(x.view(-1), distress.view(-1))\n",
    "    \n",
    "            loss_empathy = None\n",
    "            if empathy is not None:\n",
    "                loss_empathy = F.mse_loss(x_2.view(-1), empathy.view(-1))\n",
    "            \n",
    "            return (\n",
    "                SequenceClassifierOutput(\n",
    "                    loss=loss_distress,\n",
    "                    logits=x\n",
    "                ),\n",
    "                SequenceClassifierOutput(\n",
    "                    loss=loss_empathy,\n",
    "                    logits=x_2\n",
    "                )\n",
    "            )\n",
    "\n",
    "        elif self.task == tasks[1]: # distress\n",
    "            loss_empathy = None\n",
    "            if empathy is not None:\n",
    "                loss_empathy = F.mse_loss(x.view(-1), empathy.view(-1))\n",
    "                \n",
    "            loss_distress = None\n",
    "            \n",
    "            if distress is not None:\n",
    "                loss_distress = F.mse_loss(x_2.view(-1), distress.view(-1))\n",
    "    \n",
    "            \n",
    "            return (\n",
    "                SequenceClassifierOutput(\n",
    "                    loss=loss_empathy,\n",
    "                    logits=x_2\n",
    "                ),\n",
    "                SequenceClassifierOutput(\n",
    "                    loss=loss_distress,\n",
    "                    logits=x\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74223080-cf03-431f-93fd-3775064dc4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(tasks=tasks, final_task=tasks[0], lr=1e-5, batch_size=8, n_epochs=3, seed=1, save=False):\n",
    "    set_all_seeds(seed)\n",
    "    \n",
    "    model = RecurrentGuidedTransformer(n_freeze=0, task=final_task)\n",
    "    device = get_device(0)\n",
    "    model.to(device)\n",
    "\n",
    "    # print(model)\n",
    "\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "              \n",
    "    trainloader, devloader = get_data(tasks=tasks, features=features, batch_size=batch_size)\n",
    "\n",
    "    training_steps = n_epochs * len(trainloader)\n",
    "    lr_scheduler = get_scheduler(\n",
    "        \"linear\",\n",
    "        optimizer=opt,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=training_steps\n",
    "    )\n",
    "\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    corr = []\n",
    "    for epoch in range(0, n_epochs):\n",
    "        total_loss = 0.0\n",
    "        model.train()\n",
    "        for batch in trainloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            (outputs_1, outputs_2) = model(**batch)\n",
    "            loss_1 = outputs_1.loss\n",
    "            loss_2 = outputs_2.loss\n",
    "            loss_1.backward(retain_graph=True)\n",
    "            loss_2.backward()\n",
    "            \n",
    "            opt.step()\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            total_loss += loss_2.item()\n",
    "\n",
    "        train_loss.append(total_loss / len(trainloader)) # len(trainloader) == num_batches\n",
    "\n",
    "        total_loss = 0.0\n",
    "        model.eval()\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for batch in devloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            with torch.no_grad():\n",
    "                (_, outputs_2) = model(**batch)\n",
    "\n",
    "            batch_pred = [item for sublist in outputs_2.logits.tolist() for item in sublist]  #convert 2D list to 1D\n",
    "            y_pred.extend(batch_pred)\n",
    "            y_true.extend((batch[final_task].tolist()))\n",
    "            total_loss += outputs_2.loss.item()\n",
    "        \n",
    "        val_loss.append(total_loss / len(devloader))\n",
    "\n",
    "        # print(y_pred)\n",
    "        corr.append(pearsonr(y_true, y_pred))\n",
    "        print(\"pearson_r:\", corr[-1]) # -1 index refer to the last (current) correlation\n",
    "        \n",
    "        if save and epoch > 0 and (corr[-1] > max(corr[:-1])): #after first epoch, if the last score is greater than max of all but last score\n",
    "            filename = \"model\" + final_task + \".pth\"\n",
    "            torch.save(model.state_dict(), filename)\n",
    "            print(\"Saved the model as \" + filename + \" in epoch \" + str(epoch+1))\n",
    "            \n",
    "    # train-test finished\n",
    "    plot(\n",
    "        x=list(range(1, n_epochs+1)),\n",
    "        y=train_loss,\n",
    "        y2=val_loss,\n",
    "        xlabel='Epoch',\n",
    "        ylabel='Loss',\n",
    "        legend=['Training loss', 'Validation loss'],\n",
    "        save=False,\n",
    "        filename=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc6624bc-4eab-4891-a158-af0c8346e46b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.weight', 'pooler.dense.bias', 'classifier.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.weight', 'pooler.dense.bias', 'classifier.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/779 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/208 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pearson_r: 0.121\n",
      "pearson_r: 0.181\n",
      "pearson_r: 0.449\n",
      "pearson_r: 0.646\n",
      "pearson_r: 0.698\n",
      "pearson_r: 0.699\n",
      "pearson_r: 0.739\n",
      "pearson_r: 0.73\n",
      "pearson_r: 0.74\n",
      "pearson_r: 0.749\n",
      "pearson_r: 0.727\n",
      "pearson_r: 0.719\n",
      "pearson_r: 0.747\n",
      "pearson_r: 0.757\n",
      "pearson_r: 0.72\n",
      "pearson_r: 0.725\n",
      "pearson_r: 0.75\n",
      "pearson_r: 0.743\n",
      "pearson_r: 0.737\n",
      "pearson_r: 0.737\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x262.5 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(tasks=tasks, final_task=tasks[0], lr=1e-5, batch_size=8, n_epochs=20, seed=1, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8f0a8f5-8b44-442d-b7a6-4fd1729c8a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39368bbb-5ca7-49e5-83ef-54ca00522cee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.weight', 'pooler.dense.bias', 'classifier.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.weight', 'pooler.dense.bias', 'classifier.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/779 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/208 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pearson_r: 0.072\n",
      "pearson_r: 0.237\n",
      "pearson_r: 0.347\n",
      "pearson_r: 0.55\n",
      "pearson_r: 0.673\n",
      "pearson_r: 0.675\n",
      "pearson_r: 0.63\n",
      "pearson_r: 0.675\n",
      "pearson_r: 0.695\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 32\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(tasks, final_task, lr, batch_size, n_epochs, seed, save)\u001b[0m\n\u001b[1;32m     29\u001b[0m batch \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     31\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 32\u001b[0m (outputs_1, outputs_2) \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m loss_1 \u001b[38;5;241m=\u001b[39m outputs_1\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m     34\u001b[0m loss_2 \u001b[38;5;241m=\u001b[39m outputs_2\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[8], line 64\u001b[0m, in \u001b[0;36mRecurrentGuidedTransformer.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, empathy, distress)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     57\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m     distress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     62\u001b[0m ):\n\u001b[0;32m---> 64\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# print(outputs.keys())\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# will return ['logits', 'hidden_states', 'attentions']\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(outputs\u001b[38;5;241m.\u001b[39mlogits) \u001b[38;5;66;03m# output.logits aka pooled output from [CLS] token beacuse of AutoModelForSequenceClassification\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/.venv/lib/python3.11/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:1310\u001b[0m, in \u001b[0;36mDebertaV2ForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1303\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1308\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1310\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1321\u001b[0m encoder_layer \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1322\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(encoder_layer)\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/.venv/lib/python3.11/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:1082\u001b[0m, in \u001b[0;36mDebertaV2Model.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1072\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m   1074\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   1075\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1076\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1079\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   1080\u001b[0m )\n\u001b[0;32m-> 1082\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1089\u001b[0m encoded_layers \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/.venv/lib/python3.11/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:520\u001b[0m, in \u001b[0;36mDebertaV2Encoder.forward\u001b[0;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[1;32m    511\u001b[0m     output_states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    512\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    513\u001b[0m         next_kv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    517\u001b[0m         rel_embeddings,\n\u001b[1;32m    518\u001b[0m     )\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 520\u001b[0m     output_states \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnext_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    530\u001b[0m     output_states, att_m \u001b[38;5;241m=\u001b[39m output_states\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/.venv/lib/python3.11/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:362\u001b[0m, in \u001b[0;36mDebertaV2Layer.forward\u001b[0;34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    355\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    360\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    361\u001b[0m ):\n\u001b[0;32m--> 362\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    371\u001b[0m         attention_output, att_matrix \u001b[38;5;241m=\u001b[39m attention_output\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/.venv/lib/python3.11/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:293\u001b[0m, in \u001b[0;36mDebertaV2Attention.forward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    286\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m     rel_embeddings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    292\u001b[0m ):\n\u001b[0;32m--> 293\u001b[0m     self_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    302\u001b[0m         self_output, att_matrix \u001b[38;5;241m=\u001b[39m self_output\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/.venv/lib/python3.11/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:740\u001b[0m, in \u001b[0;36mDisentangledSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;66;03m# bsz x height x length x dimension\u001b[39;00m\n\u001b[1;32m    739\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m XSoftmax\u001b[38;5;241m.\u001b[39mapply(attention_scores, attention_mask, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 740\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_probs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    741\u001b[0m context_layer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(\n\u001b[1;32m    742\u001b[0m     attention_probs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, attention_probs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m), attention_probs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), value_layer\n\u001b[1;32m    743\u001b[0m )\n\u001b[1;32m    744\u001b[0m context_layer \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    745\u001b[0m     context_layer\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_attention_heads, context_layer\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m), context_layer\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    746\u001b[0m     \u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    748\u001b[0m )\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/.venv/lib/python3.11/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:234\u001b[0m, in \u001b[0;36mStableDropout.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03mCall the module\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \n\u001b[1;32m    230\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03m    x (`torch.tensor`): The input tensor to apply dropout\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_prob \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mXDropout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/.venv/lib/python3.11/site-packages/torch/autograd/function.py:506\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    505\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    510\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/.venv/lib/python3.11/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:177\u001b[0m, in \u001b[0;36mXDropout.forward\u001b[0;34m(ctx, input, local_ctx)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(ctx, \u001b[38;5;28minput\u001b[39m, local_ctx):\n\u001b[0;32m--> 177\u001b[0m     mask, dropout \u001b[38;5;241m=\u001b[39m \u001b[43mget_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_ctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     ctx\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m dropout)\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dropout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/scratch/jr19/rh2942/.venv/lib/python3.11/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:162\u001b[0m, in \u001b[0;36mget_mask\u001b[0;34m(input, local_context)\u001b[0m\n\u001b[1;32m    159\u001b[0m     mask \u001b[38;5;241m=\u001b[39m local_context\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;28;01mif\u001b[39;00m local_context\u001b[38;5;241m.\u001b[39mreuse_mask \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dropout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 162\u001b[0m     mask \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_like\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbernoulli_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mbool)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(local_context, DropoutContext):\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m local_context\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(tasks=tasks, final_task=tasks[1], lr=1e-5, batch_size=8, n_epochs=20, seed=1, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d05cdb-2361-46df-b38d-02833a44fb13",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8229495a-7e68-4745-9527-536e7ba84b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ffc32bc-45ba-435c-8e42-e3b3667f3c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(tasks=tasks, final_task=tasks[0], batch_size=8, seed=1):\n",
    "\n",
    "    model = RecurrentGuidedTransformer(n_freeze=0, task=final_task)\n",
    "    device = get_device()\n",
    "    model.to(device)\n",
    "\n",
    "    # load the trained parameters\n",
    "    filename = \"model\" + final_task + \".pth\"\n",
    "    model.load_state_dict(torch.load(filename))\n",
    "    print(f\"Loaded model: {filename}\")\n",
    "    \n",
    "    testloader = get_test_data(tasks=tasks, features=features, batch_size=batch_size)\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    for batch in testloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            (_, outputs_2) = model(**batch)\n",
    "\n",
    "        batch_pred = [item for sublist in outputs_2.logits.tolist() for item in sublist]  #convert 2D list to 1D\n",
    "        y_pred.extend(batch_pred)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dafbb40-51e8-4790-9c09-bcf88a85686a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.weight', 'pooler.dense.bias', 'classifier.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.weight', 'pooler.dense.bias', 'classifier.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model: modelempathy.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_emp = test(tasks=tasks, final_task=tasks[0], batch_size=8, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c83e347d-c338-427d-8439-6261091fdf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09a190d3-d814-48b0-bf5a-a6e117aa2741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.weight', 'pooler.dense.bias', 'classifier.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2ForSequenceClassification: ['lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.weight', 'pooler.dense.bias', 'classifier.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model: modeldistress.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_dis = test(tasks=tasks, final_task=tasks[1], batch_size=8, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87006097-cd0b-4d8e-9db8-f6e72f3f511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for submission to CodaLab\n",
    "y_pred = pd.DataFrame({\n",
    "    tasks[0]: y_pred_emp,\n",
    "    tasks[1]: y_pred_dis\n",
    "})\n",
    "y_pred.to_csv(\"./tmp/predictions_EMP.tsv\", sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b2cdf4-5b82-43aa-959f-5d994c322300",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
