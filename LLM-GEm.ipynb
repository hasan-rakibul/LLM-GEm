{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94915d97-0f63-4805-b4a3-66e94b3c5d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from utils.utils import plot, set_all_seeds\n",
    "from utils.common import DataModule, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e65bb5-f377-4664-8720-b18276ee77b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 'roberta-base'\n",
    "task = ['empathy', 'wrong_empathy'] # empathy: LLM annotation, wrong_empathy: crowdsource annotation\n",
    "# feature_to_tokenise=['demographic_essay', 'article']\n",
    "# feature_to_tokenise=['demographic', 'essay']\n",
    "feature_to_tokenise=['demographic_essay']\n",
    "\n",
    "################# COMBINED TRAIN FILE ##############\n",
    "# train_file = './data/WS22-WS23-sep-from-aug-train-gpt.tsv' # w/o augmentation\n",
    "train_file = './data/WS22-WS23-augmented-train-gpt.tsv'\n",
    "\n",
    "################# WASSA 2022 ####################\n",
    "# dev_file = './data/WS22-dev-gpt.tsv'\n",
    "# dev_label_crowd = './data/WASSA22/goldstandard_dev_2022.tsv'\n",
    "# dev_label_gpt = './data/WS22-dev-gpt.tsv'\n",
    "\n",
    "################# WASSA 2023 ####################\n",
    "dev_file = './data/WS23-dev-gpt.tsv'\n",
    "dev_label_crowd = './data/WASSA23/goldstandard_dev.tsv'\n",
    "dev_label_gpt = './data/WS23-dev-gpt.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd3e8b8-6462-4afb-8f0e-c6991ae24a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_range = [0, 42, 100, 999, 1234]\n",
    "anno_diff_range = np.arange(0, 6.5, 0.5)\n",
    "\n",
    "mode=0 # -1: crowd, 1: gpt, 0: crowd-gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bba8167-7cf2-4d66-9ecf-16800e418076",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_results = pd.DataFrame()\n",
    "\n",
    "for seed in seed_range:\n",
    "\n",
    "    set_all_seeds(seed)\n",
    "    \n",
    "    data_module = DataModule(\n",
    "        task=task,\n",
    "        checkpoint=checkpoint,\n",
    "        batch_size=16,\n",
    "        feature_to_tokenise=feature_to_tokenise,\n",
    "        seed=seed\n",
    "    )\n",
    "    \n",
    "    train_loader = data_module.dataloader(file=train_file, send_label=True, shuffle=True)\n",
    "    dev_loader = data_module.dataloader(file=dev_file, send_label=False, shuffle=False)\n",
    "\n",
    "    for anno_diff in anno_diff_range:\n",
    "        trainer = Trainer(\n",
    "            task=task,\n",
    "            checkpoint=checkpoint,\n",
    "            lr=1e-5,\n",
    "            n_epochs=10,\n",
    "            train_loader=train_loader,\n",
    "            dev_loader=dev_loader,\n",
    "            dev_label_gpt=dev_label_gpt,\n",
    "            dev_label_crowd=dev_label_crowd,\n",
    "            device_id=0,\n",
    "            anno_diff=anno_diff,\n",
    "            mode=mode\n",
    "        )\n",
    "\n",
    "        ## If we want to save model to use while testing\n",
    "        # save_as_loss = './ws23ckp/loss-llm-roberta-seed-' + str(seed) + '-anno_diff-' + str(anno_diff) + '.pth'\n",
    "        # save_as_pearson = './ws23ckp/pearson-llm-roberta-seed-' + str(seed) + '-anno_diff-' + str(anno_diff) + '.pth'\n",
    "        \n",
    "        val_pearson_r = trainer.fit(save_as_loss=None, save_as_pearson=None, dev_alpha=True)\n",
    "\n",
    "        # save as seed in index and anno_diff in columns\n",
    "        print(f'\\n----Seed {seed}, anno_diff {anno_diff}: {val_pearson_r}----\\n')\n",
    "        val_results.loc[seed, anno_diff] = val_pearson_r\n",
    "\n",
    "    # Saving in each seed to be cautious\n",
    "    # val_results.to_csv('ws23-val_results_diff_seed_anno_diff.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab15c9c9-d937-4f8a-825f-7ef384dad0f3",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc31fe9f-6869-4555-9f08-cb3b2760c545",
   "metadata": {},
   "source": [
    "## WS 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf178ba5-a3a9-4a8c-ace3-3c7df6e106d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "anno_diff = 5.0\n",
    "\n",
    "test_file = './data/PREPROCESSED-WS23-test.tsv'\n",
    "load_model = './ws23ckp/pearson-llm-roberta-seed-' + str(seed) + '-anno_diff-' + str(anno_diff) + '.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388886bc-71f5-44fc-a14d-1a78bd823c3f",
   "metadata": {},
   "source": [
    "## WS 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a008197e-4303-45c5-9b78-ee214f88ccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 1234\n",
    "# anno_diff = 6.0\n",
    "\n",
    "# test_file = './data/PREPROCESSED-WS22-test.tsv'\n",
    "# load_model = './ws22ckp/pearson-llm-roberta-seed-' + str(seed) + '-anno_diff-' + str(anno_diff) + '.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850acdfa-841d-4bba-b604-ddc67e1be542",
   "metadata": {},
   "source": [
    "## Let's test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a648e9-cd2f-4945-814a-798332b9401d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_all_seeds(seed)\n",
    "\n",
    "data_module = DataModule(\n",
    "    task=task,\n",
    "    checkpoint=checkpoint,\n",
    "    batch_size=16,\n",
    "    feature_to_tokenise=feature_to_tokenise,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "print('Working with', test_file)\n",
    "test_loader = data_module.dataloader(file=test_file, send_label=False, shuffle=False)\n",
    "\n",
    "trainer = Trainer(\n",
    "    task=task,\n",
    "    checkpoint=checkpoint,\n",
    "    lr=1e-5,\n",
    "    n_epochs=10,\n",
    "    train_loader=None,\n",
    "    dev_loader=None,\n",
    "    dev_label_gpt=None,\n",
    "    dev_label_crowd=None,\n",
    "    device_id=0,\n",
    "    anno_diff=anno_diff,\n",
    "    mode=0 # -1: crowd, 1: gpt, 0: crowd-gpt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d5d6d3-b64d-4ffa-80bb-e20306380e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Working with', load_model)\n",
    "pred = trainer.evaluate(dataloader=test_loader, load_model=load_model)\n",
    "pred_df = pd.DataFrame({'emp': pred, 'dis': pred}) # we're not predicting distress, just aligning with submission system\n",
    "pred_df.to_csv('./tmp/predictions_EMP.tsv', sep='\\t', index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e546af-dec1-4e18-b607-9f0c595a0b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd tmp\n",
    "!zip predictions.zip predictions_EMP.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca399b24-5cb5-4893-afd6-5ce7cd9ceda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm predictions_EMP.tsv predictions.zip\n",
    "%cd ../"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
