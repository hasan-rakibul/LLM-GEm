{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94915d97-0f63-4805-b4a3-66e94b3c5d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "os.chdir(\"/g/data/jr19/rh2942/text-empathy/\")\n",
    "from utils.utils import plot, set_all_seeds\n",
    "from utils.kfold import KFoldDataModule, KFoldTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80e65bb5-f377-4664-8720-b18276ee77b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 'roberta-base'\n",
    "task = ['empathy', 'wrong_empathy']\n",
    "# feature_to_tokenise=['demographic_essay', 'article']\n",
    "# feature_to_tokenise=['demographic', 'essay']\n",
    "feature_to_tokenise=['demographic_essay']\n",
    "seed = 0\n",
    "anno_diff_range = np.arange(0, 6.5, 0.5)\n",
    "\n",
    "#################### v1 dataset ###################\n",
    "filename = './data/v1-90-percent.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73c6a897-b22b-4438-9fd2-2b03d48e9dd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 16.6045936827964\n",
      "Pearson r: 0.891\n",
      "Validation loss: 0.339932382106781\n",
      "Best Pearson r: 0.891\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.8374277657650886\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.3681100904941559\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.584899975898418\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.3926880955696106\n",
      "Best Pearson r: 0.896\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.64610496734051\n",
      "Pearson r: 0.907\n",
      "Validation loss: 0.4141209125518799\n",
      "\n",
      "----Pearson r: 0.907----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 16.33154967490663\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.3298754394054413\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.814216249800743\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.41551098227500916\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.2668789828077274\n",
      "Pearson r: 0.904\n",
      "Validation loss: 0.3323436677455902\n",
      "Best Pearson r: 0.904\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.0122582088125514\n",
      "Pearson r: 0.903\n",
      "Validation loss: 0.48611682653427124\n",
      "\n",
      "----Pearson r: 0.904----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 17.123845810585834\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.35957276821136475\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.993586664504193\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.3798726499080658\n",
      "Best Pearson r: 0.896\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.358239747108297\n",
      "Pearson r: 0.904\n",
      "Validation loss: 0.34435468912124634\n",
      "Best Pearson r: 0.904\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.35589056065742\n",
      "Pearson r: 0.901\n",
      "Validation loss: 0.5545217990875244\n",
      "Best Pearson r: 0.904\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 1.9854137846764097\n",
      "Pearson r: 0.893\n",
      "Validation loss: 0.40950992703437805\n",
      "Best Pearson r: 0.904\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 1.494557537296985\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.47875913977622986\n",
      "\n",
      "----Pearson r: 0.904----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 16.479930946167478\n",
      "Pearson r: 0.014\n",
      "Validation loss: 131.40184020996094\n",
      "Best Pearson r: 0.014\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.743450566809228\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.39578977227211\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.234333151198448\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.4403795897960663\n",
      "Best Pearson r: 0.896\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.297807681433698\n",
      "Pearson r: -0.092\n",
      "Validation loss: 553.232177734375\n",
      "Best Pearson r: 0.896\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 1.8382893711962598\n",
      "Pearson r: 0.901\n",
      "Validation loss: 0.4145224690437317\n",
      "\n",
      "----Pearson r: 0.901----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 15.82098957071913\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.34275633096694946\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.548672157399198\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.37553468346595764\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 2.778536173891514\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.40834975242614746\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.054637980587939\n",
      "Pearson r: 0.905\n",
      "Validation loss: 0.39115795493125916\n",
      "\n",
      "----Pearson r: 0.905----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 15.276989850592106\n",
      "Pearson r: 0.893\n",
      "Validation loss: 0.3585785925388336\n",
      "Best Pearson r: 0.893\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.6668039890045816\n",
      "Pearson r: 0.852\n",
      "Validation loss: 0.5173333883285522\n",
      "Best Pearson r: 0.893\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.4953837952715285\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.37825316190719604\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.2270758202735412\n",
      "Pearson r: 0.905\n",
      "Validation loss: 0.3244386315345764\n",
      "Best Pearson r: 0.905\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.566530185811063\n",
      "Pearson r: 0.906\n",
      "Validation loss: 0.3710508346557617\n",
      "Best Pearson r: 0.906\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.2467103968275355\n",
      "Pearson r: 0.909\n",
      "Validation loss: 0.3590989112854004\n",
      "Best Pearson r: 0.909\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 1.903784382216474\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.38569679856300354\n",
      "\n",
      "----Pearson r: 0.909----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 14.097325489876118\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.3368297219276428\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.440076361311243\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.3630980849266052\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.258706063666242\n",
      "Pearson r: 0.9\n",
      "Validation loss: 0.34490352869033813\n",
      "Best Pearson r: 0.9\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.562235238070184\n",
      "Pearson r: 0.908\n",
      "Validation loss: 0.3478949964046478\n",
      "\n",
      "----Pearson r: 0.908----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 13.455893125939877\n",
      "Pearson r: 0.894\n",
      "Validation loss: 0.3406696021556854\n",
      "Best Pearson r: 0.894\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.554451232260846\n",
      "Pearson r: 0.894\n",
      "Validation loss: 0.3386317789554596\n",
      "Best Pearson r: 0.894\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.451725633854562\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.3519371449947357\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.81117127169954\n",
      "Pearson r: 0.907\n",
      "Validation loss: 0.3270695209503174\n",
      "Best Pearson r: 0.907\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.3548300114083798\n",
      "Pearson r: 0.908\n",
      "Validation loss: 0.3303562104701996\n",
      "Best Pearson r: 0.908\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.0064652574823256\n",
      "Pearson r: 0.903\n",
      "Validation loss: 0.3398558497428894\n",
      "Best Pearson r: 0.908\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 1.7014155514696812\n",
      "Pearson r: 0.215\n",
      "Validation loss: 20.854629516601562\n",
      "\n",
      "----Pearson r: 0.908----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 12.99112393500957\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.36155965924263\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.5958089004171656\n",
      "Pearson r: 0.886\n",
      "Validation loss: 0.35908079147338867\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3986774175725083\n",
      "Pearson r: 0.898\n",
      "Validation loss: 0.3218556046485901\n",
      "Best Pearson r: 0.898\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.9218240266150617\n",
      "Pearson r: 0.903\n",
      "Validation loss: 0.3467230200767517\n",
      "Best Pearson r: 0.903\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.5958380851339786\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.338932067155838\n",
      "Best Pearson r: 0.903\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.2699289486763323\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.364959716796875\n",
      "\n",
      "----Pearson r: 0.903----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 12.055695711298192\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.343020498752594\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.43369530109649\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.32180869579315186\n",
      "Best Pearson r: 0.896\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.187004349333175\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.3101714551448822\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.707811453240983\n",
      "Pearson r: 0.91\n",
      "Validation loss: 0.2745779752731323\n",
      "Best Pearson r: 0.91\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.3065983399431755\n",
      "Pearson r: 0.905\n",
      "Validation loss: 0.31233546137809753\n",
      "Best Pearson r: 0.91\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 1.9865551603601335\n",
      "Pearson r: 0.897\n",
      "Validation loss: 0.334626168012619\n",
      "Best Pearson r: 0.91\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 1.7275354710031063\n",
      "Pearson r: 0.83\n",
      "Validation loss: 0.7414594888687134\n",
      "\n",
      "----Pearson r: 0.91----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 11.932182882694487\n",
      "Pearson r: 0.893\n",
      "Validation loss: 0.36213353276252747\n",
      "Best Pearson r: 0.893\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.4630914609482946\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.32927873730659485\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3218572748468276\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.32667410373687744\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.0727920481499207\n",
      "Pearson r: 0.795\n",
      "Validation loss: 0.717582643032074\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.60002227286075\n",
      "Pearson r: 0.89\n",
      "Validation loss: 0.3502245545387268\n",
      "\n",
      "----Pearson r: 0.895----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 11.838717115686295\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.3797551095485687\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.489746524932537\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.315665602684021\n",
      "Best Pearson r: 0.896\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.390408309216195\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.3173893988132477\n",
      "Best Pearson r: 0.896\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.2204003321363572\n",
      "Pearson r: 0.901\n",
      "Validation loss: 0.3201289176940918\n",
      "Best Pearson r: 0.901\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.7088122735632227\n",
      "Pearson r: 0.905\n",
      "Validation loss: 0.3032868802547455\n",
      "Best Pearson r: 0.905\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.4303099164303315\n",
      "Pearson r: 0.905\n",
      "Validation loss: 0.2825493812561035\n",
      "Best Pearson r: 0.905\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 2.224191526149182\n",
      "Pearson r: 0.909\n",
      "Validation loss: 0.2862214744091034\n",
      "Best Pearson r: 0.909\n",
      "\n",
      "Epoch: 8\n",
      "Train loss: 2.006062881109562\n",
      "Pearson r: 0.904\n",
      "Validation loss: 0.2895030677318573\n",
      "Best Pearson r: 0.909\n",
      "\n",
      "Epoch: 9\n",
      "Train loss: 1.8935612953723746\n",
      "Pearson r: 0.898\n",
      "Validation loss: 0.34870871901512146\n",
      "\n",
      "----Pearson r: 0.909----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 11.888898730278015\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.3602781593799591\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.434090900928416\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.3229687809944153\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3839660959040865\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.30576637387275696\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.173958529817297\n",
      "Pearson r: 0.894\n",
      "Validation loss: 0.3395322859287262\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.751594383665856\n",
      "Pearson r: 0.915\n",
      "Validation loss: 0.26311159133911133\n",
      "Best Pearson r: 0.915\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.414589658062509\n",
      "Pearson r: 0.909\n",
      "Validation loss: 0.27903300523757935\n",
      "Best Pearson r: 0.915\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 2.163211516877438\n",
      "Pearson r: 0.912\n",
      "Validation loss: 0.26932719349861145\n",
      "Best Pearson r: 0.915\n",
      "\n",
      "Epoch: 8\n",
      "Train loss: 1.9446711090016873\n",
      "Pearson r: 0.909\n",
      "Validation loss: 0.2760830521583557\n",
      "\n",
      "----Pearson r: 0.915----\n",
      "\n",
      "Fold: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 17.45914913238363\n",
      "Pearson r: 0.016\n",
      "Validation loss: 126.1736068725586\n",
      "Best Pearson r: 0.016\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.9143050579314536\n",
      "Pearson r: 0.886\n",
      "Validation loss: 0.4092053771018982\n",
      "Best Pearson r: 0.886\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.0693281457779253\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.4182121157646179\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.061632274947268\n",
      "Pearson r: 0.892\n",
      "Validation loss: 0.3862968981266022\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 1.5800129942437435\n",
      "Pearson r: 0.886\n",
      "Validation loss: 0.4954960346221924\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 1.2482795965798357\n",
      "Pearson r: 0.89\n",
      "Validation loss: 0.5330894589424133\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 1.0301161297458283\n",
      "Pearson r: 0.065\n",
      "Validation loss: 106.44378662109375\n",
      "\n",
      "----Pearson r: 0.895----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 17.234836735623947\n",
      "Pearson r: 0.886\n",
      "Validation loss: 0.36525553464889526\n",
      "Best Pearson r: 0.886\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.967759629513355\n",
      "Pearson r: 0.889\n",
      "Validation loss: 0.39925631880760193\n",
      "Best Pearson r: 0.889\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 2.6407533617729837\n",
      "Pearson r: 0.893\n",
      "Validation loss: 0.5487707257270813\n",
      "Best Pearson r: 0.893\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 1.7920831765266174\n",
      "Pearson r: 0.891\n",
      "Validation loss: 0.5139418244361877\n",
      "\n",
      "----Pearson r: 0.893----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 16.753701311476686\n",
      "Pearson r: 0.84\n",
      "Validation loss: 0.47596976161003113\n",
      "Best Pearson r: 0.84\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.719860866982886\n",
      "Pearson r: 0.886\n",
      "Validation loss: 0.4535221755504608\n",
      "Best Pearson r: 0.886\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.4466358385187514\n",
      "Pearson r: 0.893\n",
      "Validation loss: 0.4298636317253113\n",
      "Best Pearson r: 0.893\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.4896689285623266\n",
      "Pearson r: 0.894\n",
      "Validation loss: 0.4880770444869995\n",
      "Best Pearson r: 0.894\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 1.902394323907\n",
      "Pearson r: 0.89\n",
      "Validation loss: 0.414716511964798\n",
      "Best Pearson r: 0.894\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 1.585228701538228\n",
      "Pearson r: 0.879\n",
      "Validation loss: 0.5579660534858704\n",
      "Best Pearson r: 0.894\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 1.2696457660578666\n",
      "Pearson r: 0.89\n",
      "Validation loss: 0.49364519119262695\n",
      "Best Pearson r: 0.894\n",
      "\n",
      "Epoch: 8\n",
      "Train loss: 1.0806686649931239\n",
      "Pearson r: 0.884\n",
      "Validation loss: 0.4686354696750641\n",
      "\n",
      "----Pearson r: 0.894----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 16.08071036034442\n",
      "Pearson r: 0.84\n",
      "Validation loss: 0.4773007333278656\n",
      "Best Pearson r: 0.84\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.694870981764286\n",
      "Pearson r: 0.886\n",
      "Validation loss: 0.41368380188941956\n",
      "Best Pearson r: 0.886\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.46932867105971\n",
      "Pearson r: 0.887\n",
      "Validation loss: 0.4333558976650238\n",
      "Best Pearson r: 0.887\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.719954199613409\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.3983040750026703\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 1.9478547034111429\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.5155478715896606\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 1.517923211163663\n",
      "Pearson r: 0.898\n",
      "Validation loss: 0.4977681636810303\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 1.2796945936502295\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.4114438593387604\n",
      "\n",
      "----Pearson r: 0.899----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 16.349133788271153\n",
      "Pearson r: 0.869\n",
      "Validation loss: 0.429562509059906\n",
      "Best Pearson r: 0.869\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.6591851685909513\n",
      "Pearson r: 0.885\n",
      "Validation loss: 0.4162400960922241\n",
      "Best Pearson r: 0.885\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.28058755524615\n",
      "Pearson r: 0.886\n",
      "Validation loss: 0.4041767716407776\n",
      "Best Pearson r: 0.886\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.2527429309297116\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.3572278916835785\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.469667546292569\n",
      "Pearson r: 0.898\n",
      "Validation loss: 0.37004196643829346\n",
      "Best Pearson r: 0.898\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.07231157637657\n",
      "Pearson r: 0.894\n",
      "Validation loss: 0.3682677745819092\n",
      "Best Pearson r: 0.898\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 1.822393944288822\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.4385107755661011\n",
      "\n",
      "----Pearson r: 0.898----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 15.10057838926924\n",
      "Pearson r: 0.882\n",
      "Validation loss: 0.3716960549354553\n",
      "Best Pearson r: 0.882\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.6410285234451294\n",
      "Pearson r: 0.886\n",
      "Validation loss: 0.39694905281066895\n",
      "Best Pearson r: 0.886\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.4376338923231082\n",
      "Pearson r: 0.889\n",
      "Validation loss: 0.4003404676914215\n",
      "Best Pearson r: 0.889\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.4417121962029884\n",
      "Pearson r: 0.898\n",
      "Validation loss: 0.30875876545906067\n",
      "Best Pearson r: 0.898\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 1.9108421225497063\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.3431204855442047\n",
      "Best Pearson r: 0.898\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 1.588313433084082\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.34271880984306335\n",
      "Best Pearson r: 0.898\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 1.3647159693088937\n",
      "Pearson r: 0.885\n",
      "Validation loss: 0.4097423553466797\n",
      "\n",
      "----Pearson r: 0.898----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 14.138606479827393\n",
      "Pearson r: 0.866\n",
      "Validation loss: 0.43242987990379333\n",
      "Best Pearson r: 0.866\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.4489442883653845\n",
      "Pearson r: 0.886\n",
      "Validation loss: 0.36713701486587524\n",
      "Best Pearson r: 0.886\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3113487159952206\n",
      "Pearson r: 0.887\n",
      "Validation loss: 0.38522225618362427\n",
      "Best Pearson r: 0.887\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.7027796849291374\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.393223375082016\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.136055489803882\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.3773998022079468\n",
      "\n",
      "----Pearson r: 0.902----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 13.145230227328362\n",
      "Pearson r: 0.886\n",
      "Validation loss: 0.37340107560157776\n",
      "Best Pearson r: 0.886\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.587245558170562\n",
      "Pearson r: 0.886\n",
      "Validation loss: 0.3660532832145691\n",
      "Best Pearson r: 0.886\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.2902237227622497\n",
      "Pearson r: 0.905\n",
      "Validation loss: 0.2916799485683441\n",
      "Best Pearson r: 0.905\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.572073370852369\n",
      "Pearson r: 0.905\n",
      "Validation loss: 0.29364213347435\n",
      "Best Pearson r: 0.905\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.166995108127594\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.4131629467010498\n",
      "Best Pearson r: 0.905\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 1.8194736381794543\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.30722224712371826\n",
      "\n",
      "----Pearson r: 0.905----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 13.28221888491448\n",
      "Pearson r: 0.885\n",
      "Validation loss: 0.3845158815383911\n",
      "Best Pearson r: 0.885\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.4942267537117004\n",
      "Pearson r: 0.886\n",
      "Validation loss: 0.3774280250072479\n",
      "Best Pearson r: 0.886\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3982199037328678\n",
      "Pearson r: 0.886\n",
      "Validation loss: 0.377588152885437\n",
      "Best Pearson r: 0.886\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.9412898078877876\n",
      "Pearson r: 0.904\n",
      "Validation loss: 0.3136814534664154\n",
      "Best Pearson r: 0.904\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.579643258389006\n",
      "Pearson r: 0.901\n",
      "Validation loss: 0.3160536289215088\n",
      "Best Pearson r: 0.904\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.1229761864276644\n",
      "Pearson r: 0.897\n",
      "Validation loss: 0.36872681975364685\n",
      "Best Pearson r: 0.904\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 1.8202543537667457\n",
      "Pearson r: 0.9\n",
      "Validation loss: 0.3426749110221863\n",
      "\n",
      "----Pearson r: 0.904----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 12.24336291627681\n",
      "Pearson r: 0.885\n",
      "Validation loss: 0.37782758474349976\n",
      "Best Pearson r: 0.885\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.435571759305102\n",
      "Pearson r: 0.885\n",
      "Validation loss: 0.3567204773426056\n",
      "Best Pearson r: 0.885\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3540237076739046\n",
      "Pearson r: 0.886\n",
      "Validation loss: 0.35162612795829773\n",
      "Best Pearson r: 0.886\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.299704150950655\n",
      "Pearson r: 0.887\n",
      "Validation loss: 0.35361427068710327\n",
      "Best Pearson r: 0.887\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.985972628948536\n",
      "Pearson r: 0.042\n",
      "Validation loss: 95.8916015625\n",
      "\n",
      "----Pearson r: 0.887----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 12.642444582695656\n",
      "Pearson r: 0.885\n",
      "Validation loss: 0.4161279797554016\n",
      "Best Pearson r: 0.885\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.461413637120673\n",
      "Pearson r: 0.886\n",
      "Validation loss: 0.3534541428089142\n",
      "Best Pearson r: 0.886\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.2629386490963874\n",
      "Pearson r: 0.897\n",
      "Validation loss: 0.32093545794487\n",
      "Best Pearson r: 0.897\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.0994639675667943\n",
      "Pearson r: 0.894\n",
      "Validation loss: 0.3477884829044342\n",
      "Best Pearson r: 0.897\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.7471182485844228\n",
      "Pearson r: 0.898\n",
      "Validation loss: 0.3467347025871277\n",
      "Best Pearson r: 0.898\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.3680531471333603\n",
      "Pearson r: 0.888\n",
      "Validation loss: 0.41491493582725525\n",
      "\n",
      "----Pearson r: 0.898----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 11.32311706593696\n",
      "Pearson r: 0.01\n",
      "Validation loss: 138.8453369140625\n",
      "Best Pearson r: 0.01\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.3651194115902516\n",
      "Pearson r: 0.885\n",
      "Validation loss: 0.3515293598175049\n",
      "Best Pearson r: 0.885\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3294649720191956\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.32208871841430664\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.8679916516263435\n",
      "Pearson r: 0.905\n",
      "Validation loss: 0.29567378759384155\n",
      "Best Pearson r: 0.905\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.448304937240925\n",
      "Pearson r: 0.91\n",
      "Validation loss: 0.2789880037307739\n",
      "Best Pearson r: 0.91\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.0226487117878933\n",
      "Pearson r: 0.908\n",
      "Validation loss: 0.2856009900569916\n",
      "Best Pearson r: 0.91\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 1.772679203368248\n",
      "Pearson r: 0.048\n",
      "Validation loss: inf\n",
      "Best Pearson r: 0.91\n",
      "\n",
      "Epoch: 8\n",
      "Train loss: 1.599960742795721\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.3091953694820404\n",
      "\n",
      "----Pearson r: 0.91----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 11.37416392691592\n",
      "Pearson r: 0.883\n",
      "Validation loss: 0.3809603452682495\n",
      "Best Pearson r: 0.883\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.3907643975095545\n",
      "Pearson r: 0.886\n",
      "Validation loss: 0.3469492197036743\n",
      "Best Pearson r: 0.886\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.383259250762615\n",
      "Pearson r: 0.888\n",
      "Validation loss: 0.3483249545097351\n",
      "Best Pearson r: 0.888\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.296035351271325\n",
      "Pearson r: 0.901\n",
      "Validation loss: 0.3105413615703583\n",
      "Best Pearson r: 0.901\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.7773739600435214\n",
      "Pearson r: 0.905\n",
      "Validation loss: 0.29982322454452515\n",
      "Best Pearson r: 0.905\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.3489131141216197\n",
      "Pearson r: 0.911\n",
      "Validation loss: 0.2758004367351532\n",
      "Best Pearson r: 0.911\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 2.164963126182556\n",
      "Pearson r: 0.901\n",
      "Validation loss: 0.3135486841201782\n",
      "Best Pearson r: 0.911\n",
      "\n",
      "Epoch: 8\n",
      "Train loss: 1.951990008988279\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.31589117646217346\n",
      "Best Pearson r: 0.911\n",
      "\n",
      "Epoch: 9\n",
      "Train loss: 1.767917217726403\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.3225589096546173\n",
      "\n",
      "----Pearson r: 0.911----\n",
      "\n",
      "Fold: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1588e5f547843b389cfc9b6e2f34558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1920f99f6ed1475b8d7a1949e5f2b819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 17.773318960311563\n",
      "Pearson r: 0.027\n",
      "Validation loss: 88.53922271728516\n",
      "Best Pearson r: 0.027\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 4.117259077569272\n",
      "Pearson r: 0.862\n",
      "Validation loss: 0.5450744032859802\n",
      "Best Pearson r: 0.862\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.563673831046896\n",
      "Pearson r: 0.862\n",
      "Validation loss: 0.5467582941055298\n",
      "Best Pearson r: 0.862\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.518537963958497\n",
      "Pearson r: 0.86\n",
      "Validation loss: 0.5838540196418762\n",
      "Best Pearson r: 0.862\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 3.4261725608338702\n",
      "Pearson r: 0.87\n",
      "Validation loss: 0.5096493363380432\n",
      "Best Pearson r: 0.87\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.5368612732024904\n",
      "Pearson r: 0.878\n",
      "Validation loss: 0.42102864384651184\n",
      "Best Pearson r: 0.878\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 2.156184174913041\n",
      "Pearson r: 0.867\n",
      "Validation loss: 0.6402288675308228\n",
      "Best Pearson r: 0.878\n",
      "\n",
      "Epoch: 8\n",
      "Train loss: 1.8689020161933088\n",
      "Pearson r: 0.861\n",
      "Validation loss: 0.6903083920478821\n",
      "Best Pearson r: 0.878\n",
      "\n",
      "Epoch: 9\n",
      "Train loss: 1.7291369298671155\n",
      "Pearson r: 0.878\n",
      "Validation loss: 0.5387735962867737\n",
      "\n",
      "----Pearson r: 0.878----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 17.68516675462114\n",
      "Pearson r: 0.862\n",
      "Validation loss: 0.3992009162902832\n",
      "Best Pearson r: 0.862\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 4.037387897359564\n",
      "Pearson r: 0.862\n",
      "Validation loss: 0.5121877193450928\n",
      "Best Pearson r: 0.862\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.331357882377949\n",
      "Pearson r: 0.877\n",
      "Validation loss: 0.4699579179286957\n",
      "Best Pearson r: 0.877\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.2821890172806194\n",
      "Pearson r: 0.871\n",
      "Validation loss: 0.6431710720062256\n",
      "\n",
      "----Pearson r: 0.877----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 17.191012892317264\n",
      "Pearson r: 0.861\n",
      "Validation loss: 0.3968331813812256\n",
      "Best Pearson r: 0.861\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.8978412227427706\n",
      "Pearson r: 0.862\n",
      "Validation loss: 0.48597773909568787\n",
      "Best Pearson r: 0.862\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.0540367022473762\n",
      "Pearson r: 0.873\n",
      "Validation loss: 0.5472453236579895\n",
      "Best Pearson r: 0.873\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.30339085865528\n",
      "Pearson r: 0.104\n",
      "Validation loss: 51.10649871826172\n",
      "\n",
      "----Pearson r: 0.873----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 16.07486645718838\n",
      "Pearson r: 0.861\n",
      "Validation loss: 0.3917872905731201\n",
      "Best Pearson r: 0.861\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.67885104646074\n",
      "Pearson r: 0.862\n",
      "Validation loss: 0.5087115168571472\n",
      "Best Pearson r: 0.862\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.2897052105436932\n",
      "Pearson r: 0.869\n",
      "Validation loss: 0.4809281527996063\n",
      "Best Pearson r: 0.869\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.54497987792847\n",
      "Pearson r: 0.878\n",
      "Validation loss: 0.5012688636779785\n",
      "\n",
      "----Pearson r: 0.878----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 15.95565079628153\n",
      "Pearson r: 0.861\n",
      "Validation loss: 0.3915061056613922\n",
      "Best Pearson r: 0.861\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.5392233982999275\n",
      "Pearson r: 0.862\n",
      "Validation loss: 0.5146705508232117\n",
      "Best Pearson r: 0.862\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 2.996494839800165\n",
      "Pearson r: 0.885\n",
      "Validation loss: 0.3570639491081238\n",
      "Best Pearson r: 0.885\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.0427563875279526\n",
      "Pearson r: 0.888\n",
      "Validation loss: 0.35443803668022156\n",
      "Best Pearson r: 0.888\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 1.7461708581193964\n",
      "Pearson r: 0.878\n",
      "Validation loss: 0.5058733820915222\n",
      "Best Pearson r: 0.888\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 1.3918551048065753\n",
      "Pearson r: 0.884\n",
      "Validation loss: 0.5460144877433777\n",
      "\n",
      "----Pearson r: 0.888----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 15.23194925835792\n",
      "Pearson r: 0.857\n",
      "Validation loss: 0.4146471917629242\n",
      "Best Pearson r: 0.857\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.7227569945315095\n",
      "Pearson r: 0.861\n",
      "Validation loss: 0.4689722955226898\n",
      "Best Pearson r: 0.861\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3105630075677914\n",
      "Pearson r: 0.888\n",
      "Validation loss: 0.31534767150878906\n",
      "Best Pearson r: 0.888\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.4090250033013363\n",
      "Pearson r: 0.881\n",
      "Validation loss: 0.48550331592559814\n",
      "Best Pearson r: 0.888\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 1.9057818384880716\n",
      "Pearson r: 0.893\n",
      "Validation loss: 0.38511908054351807\n",
      "Best Pearson r: 0.893\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 1.6970250752378018\n",
      "Pearson r: 0.881\n",
      "Validation loss: 0.5288453102111816\n",
      "\n",
      "----Pearson r: 0.893----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 14.0886087696603\n",
      "Pearson r: 0.861\n",
      "Validation loss: 0.38740578293800354\n",
      "Best Pearson r: 0.861\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.4135705346756793\n",
      "Pearson r: 0.764\n",
      "Validation loss: 0.8844689726829529\n",
      "Best Pearson r: 0.861\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.2165082135099046\n",
      "Pearson r: 0.875\n",
      "Validation loss: 0.37255558371543884\n",
      "Best Pearson r: 0.875\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.4759122703937773\n",
      "Pearson r: 0.882\n",
      "Validation loss: 0.44783011078834534\n",
      "Best Pearson r: 0.882\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.049707773518055\n",
      "Pearson r: 0.889\n",
      "Validation loss: 0.3988584578037262\n",
      "Best Pearson r: 0.889\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 1.7616961585714461\n",
      "Pearson r: 0.886\n",
      "Validation loss: 0.39756831526756287\n",
      "\n",
      "----Pearson r: 0.889----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 14.059770213796737\n",
      "Pearson r: 0.861\n",
      "Validation loss: 0.40369850397109985\n",
      "Best Pearson r: 0.861\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.5314130757717375\n",
      "Pearson r: 0.862\n",
      "Validation loss: 0.4367673099040985\n",
      "Best Pearson r: 0.862\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3228152990341187\n",
      "Pearson r: 0.885\n",
      "Validation loss: 0.32352718710899353\n",
      "Best Pearson r: 0.885\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.811191703410859\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.3118472397327423\n",
      "Best Pearson r: 0.896\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.293760861488099\n",
      "Pearson r: 0.876\n",
      "Validation loss: 0.47686028480529785\n",
      "Best Pearson r: 0.896\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.109251844122055\n",
      "Pearson r: 0.892\n",
      "Validation loss: 0.3482822775840759\n",
      "Best Pearson r: 0.896\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 1.7245039724289102\n",
      "Pearson r: 0.89\n",
      "Validation loss: 0.3562975525856018\n",
      "\n",
      "----Pearson r: 0.896----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 14.19187009588201\n",
      "Pearson r: 0.681\n",
      "Validation loss: 0.8461111187934875\n",
      "Best Pearson r: 0.681\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.537795662879944\n",
      "Pearson r: 0.862\n",
      "Validation loss: 0.43484801054000854\n",
      "Best Pearson r: 0.862\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.2524482734659883\n",
      "Pearson r: 0.894\n",
      "Validation loss: 0.3016807436943054\n",
      "Best Pearson r: 0.894\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.7089008511380945\n",
      "Pearson r: 0.892\n",
      "Validation loss: 0.3533101975917816\n",
      "Best Pearson r: 0.894\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.411788703279292\n",
      "Pearson r: 0.884\n",
      "Validation loss: 0.4077945947647095\n",
      "Best Pearson r: 0.894\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.1662262025031636\n",
      "Pearson r: 0.89\n",
      "Validation loss: 0.3633180260658264\n",
      "\n",
      "----Pearson r: 0.894----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 13.159356682858569\n",
      "Pearson r: 0.862\n",
      "Validation loss: 0.410160094499588\n",
      "Best Pearson r: 0.862\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.4187628652187105\n",
      "Pearson r: 0.862\n",
      "Validation loss: 0.4194389283657074\n",
      "Best Pearson r: 0.862\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.239532748435406\n",
      "Pearson r: 0.124\n",
      "Validation loss: 33.35342025756836\n",
      "Best Pearson r: 0.862\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.0856378408188516\n",
      "Pearson r: 0.874\n",
      "Validation loss: 0.4016568958759308\n",
      "\n",
      "----Pearson r: 0.874----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 12.950199487361502\n",
      "Pearson r: 0.86\n",
      "Validation loss: 0.4119097590446472\n",
      "Best Pearson r: 0.86\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.3719563268600625\n",
      "Pearson r: 0.862\n",
      "Validation loss: 0.40997809171676636\n",
      "Best Pearson r: 0.862\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.257856030413445\n",
      "Pearson r: 0.862\n",
      "Validation loss: 0.40344393253326416\n",
      "Best Pearson r: 0.862\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.250111373181039\n",
      "Pearson r: -0.028\n",
      "Validation loss: 191.41122436523438\n",
      "\n",
      "----Pearson r: 0.862----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 11.382473423125896\n",
      "Pearson r: 0.862\n",
      "Validation loss: 0.3978019058704376\n",
      "Best Pearson r: 0.862\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.3744979424679533\n",
      "Pearson r: 0.742\n",
      "Validation loss: 0.8413550853729248\n",
      "Best Pearson r: 0.862\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.269245533232993\n",
      "Pearson r: 0.862\n",
      "Validation loss: 0.3968963921070099\n",
      "Best Pearson r: 0.862\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.3105765416267072\n",
      "Pearson r: 0.756\n",
      "Validation loss: 0.8610036373138428\n",
      "\n",
      "----Pearson r: 0.862----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 11.961014255564264\n",
      "Pearson r: 0.861\n",
      "Validation loss: 0.4026639759540558\n",
      "Best Pearson r: 0.861\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.397090235923199\n",
      "Pearson r: 0.862\n",
      "Validation loss: 0.38855668902397156\n",
      "Best Pearson r: 0.862\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3214139722763223\n",
      "Pearson r: 0.863\n",
      "Validation loss: 0.39812010526657104\n",
      "Best Pearson r: 0.863\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.084761250526347\n",
      "Pearson r: 0.869\n",
      "Validation loss: 0.4312175214290619\n",
      "Best Pearson r: 0.869\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.735759700866456\n",
      "Pearson r: 0.884\n",
      "Validation loss: 0.36308735609054565\n",
      "Best Pearson r: 0.884\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.4097304521722998\n",
      "Pearson r: 0.9\n",
      "Validation loss: 0.2899537682533264\n",
      "Best Pearson r: 0.9\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 2.2311078132467066\n",
      "Pearson r: 0.897\n",
      "Validation loss: 0.31573131680488586\n",
      "Best Pearson r: 0.9\n",
      "\n",
      "Epoch: 8\n",
      "Train loss: 2.0109842425965248\n",
      "Pearson r: 0.897\n",
      "Validation loss: 0.30433931946754456\n",
      "Best Pearson r: 0.9\n",
      "\n",
      "Epoch: 9\n",
      "Train loss: 1.7971718311309814\n",
      "Pearson r: 0.893\n",
      "Validation loss: 0.3097301125526428\n",
      "\n",
      "----Pearson r: 0.9----\n",
      "\n",
      "Fold: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 17.085536008185528\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.31034940481185913\n",
      "Best Pearson r: 0.896\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.844762199736656\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.4232977032661438\n",
      "Best Pearson r: 0.896\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.351354957895076\n",
      "Pearson r: 0.91\n",
      "Validation loss: 0.28547975420951843\n",
      "Best Pearson r: 0.91\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.4472081686588045\n",
      "Pearson r: 0.912\n",
      "Validation loss: 0.33802610635757446\n",
      "Best Pearson r: 0.912\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 1.8188809619304982\n",
      "Pearson r: 0.913\n",
      "Validation loss: 0.4214382469654083\n",
      "Best Pearson r: 0.913\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 1.4481860304132421\n",
      "Pearson r: 0.905\n",
      "Validation loss: 0.39092308282852173\n",
      "\n",
      "----Pearson r: 0.913----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 16.146322113402345\n",
      "Pearson r: 0.894\n",
      "Validation loss: 0.2994897663593292\n",
      "Best Pearson r: 0.894\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.8696439798842084\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.38528841733932495\n",
      "Best Pearson r: 0.896\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.5257004093616566\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.4614908993244171\n",
      "Best Pearson r: 0.896\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.107068524715748\n",
      "Pearson r: 0.907\n",
      "Validation loss: 0.32925480604171753\n",
      "\n",
      "----Pearson r: 0.907----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 17.53315086060382\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.31140947341918945\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.8289590034079044\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.43574920296669006\n",
      "Best Pearson r: 0.896\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.471724231192406\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.44078633189201355\n",
      "Best Pearson r: 0.896\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.322720116757332\n",
      "Pearson r: 0.867\n",
      "Validation loss: 0.5338574051856995\n",
      "\n",
      "----Pearson r: 0.896----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 16.27162015184443\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.31565091013908386\n",
      "Best Pearson r: 0.896\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.7766771988665804\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.4184034764766693\n",
      "Best Pearson r: 0.896\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3188121788045195\n",
      "Pearson r: 0.909\n",
      "Validation loss: 0.31581541895866394\n",
      "Best Pearson r: 0.909\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.441284454883413\n",
      "Pearson r: 0.906\n",
      "Validation loss: 0.4406093955039978\n",
      "\n",
      "----Pearson r: 0.909----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 16.177221698963894\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.3246304988861084\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.7166857947694494\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.3783544898033142\n",
      "Best Pearson r: 0.896\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.2661916955988457\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.40105995535850525\n",
      "Best Pearson r: 0.896\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.121956673074276\n",
      "Pearson r: 0.906\n",
      "Validation loss: 0.31746453046798706\n",
      "\n",
      "----Pearson r: 0.906----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 15.451412545873763\n",
      "Pearson r: 0.851\n",
      "Validation loss: 0.41700005531311035\n",
      "Best Pearson r: 0.851\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.7705863384490317\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.359666645526886\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.4608047566515334\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.4012780785560608\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.2087779882106373\n",
      "Pearson r: 0.912\n",
      "Validation loss: 0.2874731719493866\n",
      "Best Pearson r: 0.912\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.4496429904978325\n",
      "Pearson r: 0.913\n",
      "Validation loss: 0.28244417905807495\n",
      "Best Pearson r: 0.913\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 1.9993090179372341\n",
      "Pearson r: 0.916\n",
      "Validation loss: 0.33007922768592834\n",
      "Best Pearson r: 0.916\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 1.8136838890136557\n",
      "Pearson r: 0.91\n",
      "Validation loss: 0.34437501430511475\n",
      "\n",
      "----Pearson r: 0.916----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 14.446062222440192\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.3161708116531372\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.5519101010992173\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.3418174982070923\n",
      "Best Pearson r: 0.896\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.2277655601501465\n",
      "Pearson r: 0.905\n",
      "Validation loss: 0.3468870222568512\n",
      "Best Pearson r: 0.905\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.635837326658533\n",
      "Pearson r: 0.91\n",
      "Validation loss: 0.3672359585762024\n",
      "\n",
      "----Pearson r: 0.91----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 13.290305708317046\n",
      "Pearson r: 0.87\n",
      "Validation loss: 0.36513006687164307\n",
      "Best Pearson r: 0.87\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.663476124722907\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.31661292910575867\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.546676538092025\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.31875285506248474\n",
      "Best Pearson r: 0.896\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.4406229511220405\n",
      "Pearson r: 0.901\n",
      "Validation loss: 0.2912037670612335\n",
      "Best Pearson r: 0.901\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.982729452721616\n",
      "Pearson r: 0.914\n",
      "Validation loss: 0.26700448989868164\n",
      "Best Pearson r: 0.914\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.3436944605188166\n",
      "Pearson r: 0.921\n",
      "Validation loss: 0.26085805892944336\n",
      "Best Pearson r: 0.921\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 2.150033339541009\n",
      "Pearson r: 0.92\n",
      "Validation loss: 0.2617299556732178\n",
      "Best Pearson r: 0.921\n",
      "\n",
      "Epoch: 8\n",
      "Train loss: 1.8746684180929305\n",
      "Pearson r: 0.917\n",
      "Validation loss: 0.3028229773044586\n",
      "\n",
      "----Pearson r: 0.921----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 13.451374081855125\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.3159426748752594\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.499839502446195\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.3375420570373535\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.45685923479973\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.30330705642700195\n",
      "Best Pearson r: 0.896\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.4428007158827274\n",
      "Pearson r: 0.89\n",
      "Validation loss: 0.3453012704849243\n",
      "Best Pearson r: 0.896\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 3.453146532494971\n",
      "Pearson r: 0.9\n",
      "Validation loss: 0.29840800166130066\n",
      "Best Pearson r: 0.9\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.974820768579524\n",
      "Pearson r: 0.917\n",
      "Validation loss: 0.2483624368906021\n",
      "Best Pearson r: 0.917\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 2.651140791304568\n",
      "Pearson r: 0.917\n",
      "Validation loss: 0.25223350524902344\n",
      "Best Pearson r: 0.917\n",
      "\n",
      "Epoch: 8\n",
      "Train loss: 2.4371553862348514\n",
      "Pearson r: 0.91\n",
      "Validation loss: 0.3052023947238922\n",
      "Best Pearson r: 0.917\n",
      "\n",
      "Epoch: 9\n",
      "Train loss: 2.2369408442619\n",
      "Pearson r: 0.913\n",
      "Validation loss: 0.283869206905365\n",
      "\n",
      "----Pearson r: 0.917----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 12.10707062863289\n",
      "Pearson r: 0.894\n",
      "Validation loss: 0.3103187680244446\n",
      "Best Pearson r: 0.894\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.481231688184941\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.3221394717693329\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3758474994213024\n",
      "Pearson r: 0.894\n",
      "Validation loss: 0.3354830741882324\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.314223655994902\n",
      "Pearson r: 0.904\n",
      "Validation loss: 0.2799338102340698\n",
      "Best Pearson r: 0.904\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.940587581472194\n",
      "Pearson r: 0.904\n",
      "Validation loss: 0.33309781551361084\n",
      "Best Pearson r: 0.904\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.5915937601251806\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.290646493434906\n",
      "Best Pearson r: 0.904\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 2.2884349822998047\n",
      "Pearson r: 0.906\n",
      "Validation loss: 0.25351276993751526\n",
      "Best Pearson r: 0.906\n",
      "\n",
      "Epoch: 8\n",
      "Train loss: 2.1602425239187606\n",
      "Pearson r: 0.914\n",
      "Validation loss: 0.250169038772583\n",
      "Best Pearson r: 0.914\n",
      "\n",
      "Epoch: 9\n",
      "Train loss: 2.0266795056931515\n",
      "Pearson r: 0.916\n",
      "Validation loss: 0.2643119692802429\n",
      "Best Pearson r: 0.916\n",
      "\n",
      "Epoch: 10\n",
      "Train loss: 1.9556812884959769\n",
      "Pearson r: 0.905\n",
      "Validation loss: 0.3349572420120239\n",
      "\n",
      "----Pearson r: 0.916----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 12.633280444652476\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.3148373067378998\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.4581934936503145\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.31083589792251587\n",
      "Best Pearson r: 0.896\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3450161484961813\n",
      "Pearson r: 0.905\n",
      "Validation loss: 0.2830469310283661\n",
      "Best Pearson r: 0.905\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.9073531297927206\n",
      "Pearson r: 0.916\n",
      "Validation loss: 0.249210387468338\n",
      "Best Pearson r: 0.916\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.5647840753514717\n",
      "Pearson r: 0.914\n",
      "Validation loss: 0.27046844363212585\n",
      "Best Pearson r: 0.916\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.301417142786878\n",
      "Pearson r: 0.915\n",
      "Validation loss: 0.2859609127044678\n",
      "Best Pearson r: 0.916\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 2.0481612948661154\n",
      "Pearson r: -0.071\n",
      "Validation loss: 444.6124267578125\n",
      "\n",
      "----Pearson r: 0.916----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 11.531380209516971\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.3180144429206848\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.5353902362762613\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.3050328195095062\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.415665698812363\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.2985982894897461\n",
      "Best Pearson r: 0.896\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.346462740543041\n",
      "Pearson r: 0.904\n",
      "Validation loss: 0.2726901173591614\n",
      "Best Pearson r: 0.904\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 3.090125340096494\n",
      "Pearson r: 0.915\n",
      "Validation loss: 0.24506376683712006\n",
      "Best Pearson r: 0.915\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.6451393340496305\n",
      "Pearson r: 0.922\n",
      "Validation loss: 0.22337092459201813\n",
      "Best Pearson r: 0.922\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 2.441250832156932\n",
      "Pearson r: 0.916\n",
      "Validation loss: 0.24837565422058105\n",
      "Best Pearson r: 0.922\n",
      "\n",
      "Epoch: 8\n",
      "Train loss: 2.1549440083351543\n",
      "Pearson r: 0.916\n",
      "Validation loss: 0.2588174045085907\n",
      "Best Pearson r: 0.922\n",
      "\n",
      "Epoch: 9\n",
      "Train loss: 2.085710660574284\n",
      "Pearson r: 0.918\n",
      "Validation loss: 0.25403645634651184\n",
      "\n",
      "----Pearson r: 0.922----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 11.495039128242656\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.3309481143951416\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.4594913759130113\n",
      "Pearson r: 0.777\n",
      "Validation loss: 0.773464560508728\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.4174305187894944\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.2867142856121063\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.412344791787736\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.2930101454257965\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 3.128704622704932\n",
      "Pearson r: 0.888\n",
      "Validation loss: 0.3268570005893707\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.791792394632989\n",
      "Pearson r: 0.913\n",
      "Validation loss: 0.2634487748146057\n",
      "Best Pearson r: 0.913\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 2.4632273925111647\n",
      "Pearson r: 0.919\n",
      "Validation loss: 0.23353812098503113\n",
      "Best Pearson r: 0.919\n",
      "\n",
      "Epoch: 8\n",
      "Train loss: 2.234007728860733\n",
      "Pearson r: 0.914\n",
      "Validation loss: 0.25476157665252686\n",
      "Best Pearson r: 0.919\n",
      "\n",
      "Epoch: 9\n",
      "Train loss: 2.160414240461715\n",
      "Pearson r: 0.07\n",
      "Validation loss: inf\n",
      "Best Pearson r: 0.919\n",
      "\n",
      "Epoch: 10\n",
      "Train loss: 1.940200572952311\n",
      "Pearson r: 0.914\n",
      "Validation loss: 0.2395649403333664\n",
      "\n",
      "----Pearson r: 0.919----\n",
      "\n",
      "Fold: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 16.606052561009182\n",
      "Pearson r: 0.888\n",
      "Validation loss: 0.37616777420043945\n",
      "Best Pearson r: 0.888\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.960647689535263\n",
      "Train loss: 1.6007719103326188\n",
      "Pearson r: 0.888\n",
      "Validation loss: 0.514047384262085\n",
      "\n",
      "----Pearson r: 0.899----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 17.186753049809884\n",
      "Pearson r: 0.888\n",
      "Validation loss: 0.37384775280952454\n",
      "Best Pearson r: 0.888\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.9155295567309603\n",
      "Pearson r: 0.888\n",
      "Validation loss: 0.4599415957927704\n",
      "Best Pearson r: 0.888\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.626266617724236\n",
      "Pearson r: 0.89\n",
      "Validation loss: 0.4084523916244507\n",
      "Best Pearson r: 0.89\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.739779829978943\n",
      "Pearson r: 0.884\n",
      "Validation loss: 0.3838757872581482\n",
      "\n",
      "----Pearson r: 0.89----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 17.190596763123857\n",
      "Pearson r: 0.723\n",
      "Validation loss: 0.829387366771698\n",
      "Best Pearson r: 0.723\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.849277008087077\n",
      "Pearson r: 0.889\n",
      "Validation loss: 0.44130808115005493\n",
      "Best Pearson r: 0.889\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.2386476752605846\n",
      "Pearson r: 0.892\n",
      "Validation loss: 0.45575207471847534\n",
      "Best Pearson r: 0.892\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.303334705373074\n",
      "Pearson r: 0.894\n",
      "Validation loss: 0.5109694004058838\n",
      "Best Pearson r: 0.894\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 1.8159639524652602\n",
      "Pearson r: 0.879\n",
      "Validation loss: 0.4279148578643799\n",
      "Best Pearson r: 0.894\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 1.5229847364603204\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.45977023243904114\n",
      "Best Pearson r: 0.896\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 1.257912296564021\n",
      "Pearson r: 0.883\n",
      "Validation loss: 0.43952688574790955\n",
      "Best Pearson r: 0.896\n",
      "\n",
      "Epoch: 8\n",
      "Train loss: 1.0891106889602986\n",
      "Pearson r: -0.054\n",
      "Validation loss: 412.02294921875\n",
      "\n",
      "----Pearson r: 0.896----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 16.06225008913811\n",
      "Pearson r: 0.888\n",
      "Validation loss: 0.363940954208374\n",
      "Best Pearson r: 0.888\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.699773514524419\n",
      "Pearson r: 0.806\n",
      "Validation loss: 0.8255618810653687\n",
      "Best Pearson r: 0.888\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.438376949822649\n",
      "Pearson r: 0.889\n",
      "Validation loss: 0.4100784361362457\n",
      "Best Pearson r: 0.889\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.7820584437948592\n",
      "Pearson r: 0.898\n",
      "Validation loss: 0.40632426738739014\n",
      "\n",
      "----Pearson r: 0.898----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 16.003807169325807\n",
      "Pearson r: -0.011\n",
      "Validation loss: 211.7571258544922\n",
      "Best Pearson r: -0.011\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.5565007405078157\n",
      "Pearson r: 0.888\n",
      "Validation loss: 0.4114525318145752\n",
      "Best Pearson r: 0.888\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3021788571743254\n",
      "Pearson r: 0.883\n",
      "Validation loss: 0.4334234595298767\n",
      "Best Pearson r: 0.888\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.6683782009368247\n",
      "Pearson r: 0.894\n",
      "Validation loss: 0.41823020577430725\n",
      "Best Pearson r: 0.894\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 1.9816920731930023\n",
      "Pearson r: 0.89\n",
      "Validation loss: 0.386716365814209\n",
      "Best Pearson r: 0.894\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 1.6905236510520285\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.4748872220516205\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 1.497537891281412\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.41542187333106995\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 8\n",
      "Train loss: 1.244496945371019\n",
      "Pearson r: 0.892\n",
      "Validation loss: 0.4118059277534485\n",
      "\n",
      "----Pearson r: 0.895----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 14.498089696498628\n",
      "Pearson r: 0.888\n",
      "Validation loss: 0.37250852584838867\n",
      "Best Pearson r: 0.888\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.677600231576473\n",
      "Pearson r: 0.889\n",
      "Validation loss: 0.3813380300998688\n",
      "Best Pearson r: 0.889\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.1653307879224735\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.3704533874988556\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.31178295548926\n",
      "Pearson r: 0.893\n",
      "Validation loss: 0.38640838861465454\n",
      "\n",
      "----Pearson r: 0.895----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 14.609330813935463\n",
      "Pearson r: 0.889\n",
      "Validation loss: 0.37135326862335205\n",
      "Best Pearson r: 0.889\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.4724010799793485\n",
      "Pearson r: 0.888\n",
      "Validation loss: 0.3862740099430084\n",
      "Best Pearson r: 0.889\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3170520650579576\n",
      "Pearson r: 0.891\n",
      "Validation loss: 0.3790224492549896\n",
      "Best Pearson r: 0.891\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.646236555373415\n",
      "Pearson r: 0.897\n",
      "Validation loss: 0.3755575716495514\n",
      "\n",
      "----Pearson r: 0.897----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 13.759167009211602\n",
      "Pearson r: 0.886\n",
      "Validation loss: 0.3961672782897949\n",
      "Best Pearson r: 0.886\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.53858372505675\n",
      "Pearson r: 0.888\n",
      "Validation loss: 0.3667292296886444\n",
      "Best Pearson r: 0.888\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.410546046622256\n",
      "Pearson r: 0.084\n",
      "Validation loss: 63.359928131103516\n",
      "Best Pearson r: 0.888\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.3010089346703064\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.342524915933609\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.6904376098450196\n",
      "Pearson r: 0.897\n",
      "Validation loss: 0.32389238476753235\n",
      "Best Pearson r: 0.897\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.3057195436447224\n",
      "Pearson r: 0.893\n",
      "Validation loss: 0.3948122560977936\n",
      "Best Pearson r: 0.897\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 1.99213807443355\n",
      "Pearson r: 0.886\n",
      "Validation loss: 0.3852488696575165\n",
      "Best Pearson r: 0.897\n",
      "\n",
      "Epoch: 8\n",
      "Train loss: 1.7070063916926688\n",
      "Pearson r: 0.891\n",
      "Validation loss: 0.38138726353645325\n",
      "\n",
      "----Pearson r: 0.897----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 12.479735161395784\n",
      "Pearson r: 0.888\n",
      "Validation loss: 0.37733036279678345\n",
      "Best Pearson r: 0.888\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.5300595684254423\n",
      "Pearson r: 0.888\n",
      "Validation loss: 0.35802188515663147\n",
      "Best Pearson r: 0.888\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3136799931526184\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.3078281879425049\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.6901430665178503\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.3242216110229492\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.3371446595547045\n",
      "Pearson r: 0.034\n",
      "Validation loss: 126.34530639648438\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.048439476718294\n",
      "Pearson r: 0.901\n",
      "Validation loss: 0.316548228263855\n",
      "\n",
      "----Pearson r: 0.902----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 12.4621411003965\n",
      "Pearson r: 0.864\n",
      "Validation loss: 0.43294888734817505\n",
      "Best Pearson r: 0.864\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.3618716813148337\n",
      "Pearson r: 0.888\n",
      "Validation loss: 0.36045265197753906\n",
      "Best Pearson r: 0.888\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3050299882888794\n",
      "Pearson r: 0.888\n",
      "Validation loss: 0.36442169547080994\n",
      "Best Pearson r: 0.888\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.318481295666796\n",
      "Pearson r: 0.891\n",
      "Validation loss: 0.3449556529521942\n",
      "Best Pearson r: 0.891\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.903489629004864\n",
      "Pearson r: 0.9\n",
      "Validation loss: 0.32006680965423584\n",
      "Best Pearson r: 0.9\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.562128961086273\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.3338300585746765\n",
      "Best Pearson r: 0.9\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 2.348409301423012\n",
      "Pearson r: 0.9\n",
      "Validation loss: 0.3387679159641266\n",
      "Best Pearson r: 0.9\n",
      "\n",
      "Epoch: 8\n",
      "Train loss: 2.186410974948964\n",
      "Pearson r: 0.904\n",
      "Validation loss: 0.31676697731018066\n",
      "\n",
      "----Pearson r: 0.904----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 12.911513503561629\n",
      "Pearson r: 0.027\n",
      "Validation loss: 93.59156799316406\n",
      "Best Pearson r: 0.027\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.4471684225062105\n",
      "Pearson r: 0.889\n",
      "Validation loss: 0.34633901715278625\n",
      "Best Pearson r: 0.889\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.2833215036290757\n",
      "Pearson r: 0.893\n",
      "Validation loss: 0.34425219893455505\n",
      "Best Pearson r: 0.893\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.898631878355716\n",
      "Pearson r: 0.897\n",
      "Validation loss: 0.33202672004699707\n",
      "Best Pearson r: 0.897\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.5871139232148517\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.3315880000591278\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.264255277653958\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.33441805839538574\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 2.0635788060249167\n",
      "Pearson r: 0.905\n",
      "Validation loss: 0.30795541405677795\n",
      "Best Pearson r: 0.905\n",
      "\n",
      "Epoch: 8\n",
      "Train loss: 1.8731187144492536\n",
      "Pearson r: 0.907\n",
      "Validation loss: 0.2970101535320282\n",
      "Best Pearson r: 0.907\n",
      "\n",
      "Epoch: 9\n",
      "Train loss: 1.7270097409157044\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.307781845331192\n",
      "Best Pearson r: 0.907\n",
      "\n",
      "Epoch: 10\n",
      "Train loss: 1.6312314005608255\n",
      "Pearson r: 0.9\n",
      "Validation loss: 0.32881319522857666\n",
      "Best Pearson r: 0.907\n",
      "\n",
      "\n",
      "----Pearson r: 0.907----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 12.018643620166372\n",
      "Pearson r: 0.888\n",
      "Validation loss: 0.4153274595737457\n",
      "Best Pearson r: 0.888\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.465052759393733\n",
      "Pearson r: 0.889\n",
      "Validation loss: 0.3469066023826599\n",
      "Best Pearson r: 0.889\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.141052227070991\n",
      "Pearson r: 0.897\n",
      "Validation loss: 0.32348179817199707\n",
      "Best Pearson r: 0.897\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.6987676284414657\n",
      "Pearson r: 0.901\n",
      "Validation loss: 0.3401104807853699\n",
      "Best Pearson r: 0.901\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.395905914458823\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.3158637583255768\n",
      "Best Pearson r: 0.901\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.084428050416581\n",
      "Pearson r: 0.892\n",
      "Validation loss: 0.34368789196014404\n",
      "\n",
      "----Pearson r: 0.901----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 11.4399541286712\n",
      "Pearson r: 0.888\n",
      "Validation loss: 0.40244221687316895\n",
      "Best Pearson r: 0.888\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.410486526945804\n",
      "Pearson r: 0.888\n",
      "Validation loss: 0.35048288106918335\n",
      "Best Pearson r: 0.888\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3511918960733618\n",
      "Pearson r: 0.888\n",
      "Validation loss: 0.3496442437171936\n",
      "Best Pearson r: 0.888\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.325648453641445\n",
      "Pearson r: 0.898\n",
      "Validation loss: 0.32062119245529175\n",
      "Best Pearson r: 0.898\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.8980714615355145\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.3038426339626312\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.6264420012210277\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.34289199113845825\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 2.418538232433035\n",
      "Pearson r: 0.904\n",
      "Validation loss: 0.2944904565811157\n",
      "Best Pearson r: 0.904\n",
      "\n",
      "Epoch: 8\n",
      "Train loss: 2.219611492562801\n",
      "Pearson r: 0.901\n",
      "Validation loss: 0.3130055367946625\n",
      "\n",
      "----Pearson r: 0.904----\n",
      "\n",
      "Fold: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 16.802854304618023\n",
      "Pearson r: 0.883\n",
      "Validation loss: 0.3838236331939697\n",
      "Best Pearson r: 0.883\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.9265104887333324\n",
      "Pearson r: 0.883\n",
      "Validation loss: 0.4477394223213196\n",
      "Best Pearson r: 0.883\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 2.900756507477862\n",
      "Pearson r: 0.903\n",
      "Validation loss: 0.4010057747364044\n",
      "Best Pearson r: 0.903\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 1.9971256110262363\n",
      "Pearson r: 0.892\n",
      "Validation loss: 0.5182584524154663\n",
      "\n",
      "----Pearson r: 0.903----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 17.156178707772114\n",
      "Pearson r: 0.883\n",
      "Validation loss: 0.38754767179489136\n",
      "Best Pearson r: 0.883\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 4.016093994708771\n",
      "Pearson r: 0.883\n",
      "Validation loss: 0.4532548487186432\n",
      "Best Pearson r: 0.883\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.2715207389060486\n",
      "Pearson r: 0.9\n",
      "Validation loss: 0.3700854778289795\n",
      "Best Pearson r: 0.9\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.157197259842081\n",
      "Pearson r: 0.901\n",
      "Validation loss: 0.4237106740474701\n",
      "Best Pearson r: 0.901\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 1.6291309557062514\n",
      "Pearson r: 0.897\n",
      "Validation loss: 0.5106427669525146\n",
      "Best Pearson r: 0.901\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 1.3211284267141463\n",
      "Pearson r: 0.903\n",
      "Validation loss: 0.4151472747325897\n",
      "\n",
      "----Pearson r: 0.903----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 17.519923265944136\n",
      "Pearson r: 0.883\n",
      "Validation loss: 0.3894580900669098\n",
      "Best Pearson r: 0.883\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.8425654578716197\n",
      "Pearson r: 0.883\n",
      "Validation loss: 0.4771278202533722\n",
      "Best Pearson r: 0.883\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.481713236646449\n",
      "Pearson r: 0.883\n",
      "Validation loss: 0.47868141531944275\n",
      "Best Pearson r: 0.883\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.9509706890329404\n",
      "Pearson r: 0.9\n",
      "Validation loss: 0.36977848410606384\n",
      "Best Pearson r: 0.9\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.054699310596953\n",
      "Pearson r: 0.901\n",
      "Validation loss: 0.4795120656490326\n",
      "Best Pearson r: 0.901\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 1.7146666665026482\n",
      "Pearson r: 0.909\n",
      "Validation loss: 0.45815011858940125\n",
      "Best Pearson r: 0.909\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 1.4132190099421968\n",
      "Pearson r: 0.909\n",
      "Validation loss: 0.46408772468566895\n",
      "\n",
      "----Pearson r: 0.909----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 16.20236668180912\n",
      "Pearson r: 0.881\n",
      "Validation loss: 0.3848957121372223\n",
      "Best Pearson r: 0.881\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.6564826141012476\n",
      "Pearson r: 0.883\n",
      "Validation loss: 0.4365340769290924\n",
      "Best Pearson r: 0.883\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.332622544562563\n",
      "Pearson r: 0.903\n",
      "Validation loss: 0.31838977336883545\n",
      "Best Pearson r: 0.903\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.4072983480514365\n",
      "Pearson r: 0.906\n",
      "Validation loss: 0.4212840497493744\n",
      "Best Pearson r: 0.906\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 1.8572905558220885\n",
      "Pearson r: 0.906\n",
      "Validation loss: 0.35572752356529236\n",
      "Best Pearson r: 0.906\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 1.5083756865339075\n",
      "Pearson r: 0.907\n",
      "Validation loss: 0.36452746391296387\n",
      "\n",
      "----Pearson r: 0.907----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 15.559822531456643\n",
      "Pearson r: 0.878\n",
      "Validation loss: 0.3914506137371063\n",
      "Best Pearson r: 0.878\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.5066958932166403\n",
      "Pearson r: 0.875\n",
      "Validation loss: 0.46961817145347595\n",
      "Best Pearson r: 0.878\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.077460248419579\n",
      "Pearson r: 0.887\n",
      "Validation loss: 0.4838334321975708\n",
      "Best Pearson r: 0.887\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.2378427138988006\n",
      "Pearson r: 0.91\n",
      "Validation loss: 0.3357419967651367\n",
      "Best Pearson r: 0.91\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 1.8510129908297925\n",
      "Pearson r: 0.905\n",
      "Validation loss: 0.46216437220573425\n",
      "Best Pearson r: 0.91\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 1.568317562975782\n",
      "Pearson r: 0.911\n",
      "Validation loss: 0.36152854561805725\n",
      "Best Pearson r: 0.911\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 1.319226601022355\n",
      "Pearson r: 0.906\n",
      "Validation loss: 0.4072687327861786\n",
      "\n",
      "----Pearson r: 0.911----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 14.290337187178592\n",
      "Pearson r: 0.882\n",
      "Validation loss: 0.3764496445655823\n",
      "Best Pearson r: 0.882\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.588993688847156\n",
      "Pearson r: 0.884\n",
      "Validation loss: 0.401042103767395\n",
      "Best Pearson r: 0.884\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.411358010261617\n",
      "Pearson r: -0.098\n",
      "Validation loss: 606.1356201171875\n",
      "Best Pearson r: 0.884\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.536305348923866\n",
      "Pearson r: 0.904\n",
      "Validation loss: 0.37859559059143066\n",
      "\n",
      "----Pearson r: 0.904----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 13.731930050444095\n",
      "Pearson r: 0.883\n",
      "Validation loss: 0.3672720491886139\n",
      "Best Pearson r: 0.883\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.414472005468734\n",
      "Pearson r: 0.884\n",
      "Validation loss: 0.38333845138549805\n",
      "Best Pearson r: 0.884\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 2.87369760046614\n",
      "Pearson r: 0.9\n",
      "Validation loss: 0.419317364692688\n",
      "Best Pearson r: 0.9\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.3923977283721274\n",
      "Pearson r: 0.908\n",
      "Validation loss: 0.3664793372154236\n",
      "\n",
      "----Pearson r: 0.908----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 14.118157589689215\n",
      "Pearson r: 0.883\n",
      "Validation loss: 0.4238406717777252\n",
      "Best Pearson r: 0.883\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.6621844311977956\n",
      "Pearson r: 0.035\n",
      "Validation loss: 126.43836975097656\n",
      "Best Pearson r: 0.883\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.4609144342706557\n",
      "Pearson r: 0.883\n",
      "Validation loss: 0.3896188735961914\n",
      "Best Pearson r: 0.883\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.0408078749129115\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.3424312472343445\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.6428582566849728\n",
      "Pearson r: 0.897\n",
      "Validation loss: 0.34505516290664673\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.346283367973693\n",
      "Pearson r: 0.901\n",
      "Validation loss: 0.327134370803833\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 2.162558298795781\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.3647191822528839\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 8\n",
      "Train loss: 1.9830218997407467\n",
      "Pearson r: 0.901\n",
      "Validation loss: 0.35835158824920654\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 9\n",
      "Train loss: 1.8523413431137166\n",
      "Pearson r: 0.907\n",
      "Validation loss: 0.3095184564590454\n",
      "Best Pearson r: 0.907\n",
      "\n",
      "Epoch: 10\n",
      "Train loss: 1.6841920202082776\n",
      "Pearson r: 0.898\n",
      "Validation loss: 0.3679254651069641\n",
      "Best Pearson r: 0.907\n",
      "\n",
      "\n",
      "----Pearson r: 0.907----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 12.784164624011263\n",
      "Pearson r: 0.883\n",
      "Validation loss: 0.4056592285633087\n",
      "Best Pearson r: 0.883\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.5232055022361433\n",
      "Pearson r: 0.883\n",
      "Validation loss: 0.36897385120391846\n",
      "Best Pearson r: 0.883\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3418042900714466\n",
      "Pearson r: 0.867\n",
      "Validation loss: 0.4175507426261902\n",
      "Best Pearson r: 0.883\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.211093362341536\n",
      "Pearson r: 0.915\n",
      "Validation loss: 0.2682638168334961\n",
      "Best Pearson r: 0.915\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.5395923992420766\n",
      "Pearson r: 0.916\n",
      "Validation loss: 0.27131667733192444\n",
      "Best Pearson r: 0.916\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.3183421904736377\n",
      "Pearson r: 0.915\n",
      "Validation loss: 0.2900514304637909\n",
      "Best Pearson r: 0.916\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 1.9946983107861052\n",
      "Pearson r: 0.909\n",
      "Validation loss: 0.3529052138328552\n",
      "\n",
      "----Pearson r: 0.916----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 12.144699507571282\n",
      "Pearson r: 0.882\n",
      "Validation loss: 0.390875905752182\n",
      "Best Pearson r: 0.882\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.42991536982516\n",
      "Pearson r: 0.883\n",
      "Validation loss: 0.3628867268562317\n",
      "Best Pearson r: 0.883\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.2759950731662992\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.3218727707862854\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.010798102997719\n",
      "Pearson r: 0.907\n",
      "Validation loss: 0.3091849386692047\n",
      "Best Pearson r: 0.907\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.5966034366729414\n",
      "Pearson r: 0.921\n",
      "Validation loss: 0.24573932588100433\n",
      "Best Pearson r: 0.921\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.4040171954225986\n",
      "Pearson r: 0.919\n",
      "Validation loss: 0.27547040581703186\n",
      "Best Pearson r: 0.921\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 2.1716762819188706\n",
      "Pearson r: 0.922\n",
      "Validation loss: 0.25739768147468567\n",
      "Best Pearson r: 0.922\n",
      "\n",
      "Epoch: 8\n",
      "Train loss: 1.8640104957083439\n",
      "Pearson r: 0.918\n",
      "Validation loss: 0.29153162240982056\n",
      "\n",
      "----Pearson r: 0.922----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 12.135023867830316\n",
      "Pearson r: 0.881\n",
      "Validation loss: 0.39281320571899414\n",
      "Best Pearson r: 0.881\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.336827653519651\n",
      "Pearson r: 0.772\n",
      "Validation loss: 0.8232182264328003\n",
      "Best Pearson r: 0.881\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 2.9475939159697675\n",
      "Pearson r: 0.915\n",
      "Validation loss: 0.2678713798522949\n",
      "Best Pearson r: 0.915\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.584327233598587\n",
      "Pearson r: 0.924\n",
      "Validation loss: 0.23437201976776123\n",
      "Best Pearson r: 0.924\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.3130811066069503\n",
      "Pearson r: 0.041\n",
      "Validation loss: 98.40069580078125\n",
      "Best Pearson r: 0.924\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.054165449548275\n",
      "Pearson r: 0.921\n",
      "Validation loss: 0.2692650854587555\n",
      "Best Pearson r: 0.924\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 1.7741331331273342\n",
      "Pearson r: 0.045\n",
      "Validation loss: 103.5028076171875\n",
      "\n",
      "----Pearson r: 0.924----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 11.637092298649726\n",
      "Pearson r: 0.881\n",
      "Validation loss: 0.4126901924610138\n",
      "Best Pearson r: 0.881\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.399323878136087\n",
      "Pearson r: 0.883\n",
      "Validation loss: 0.3624142110347748\n",
      "Best Pearson r: 0.883\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3177369465219213\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.32449036836624146\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.8402356251757195\n",
      "Pearson r: 0.915\n",
      "Validation loss: 0.2689293324947357\n",
      "Best Pearson r: 0.915\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.4532100304644158\n",
      "Pearson r: 0.919\n",
      "Validation loss: 0.2615399658679962\n",
      "Best Pearson r: 0.919\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.1159151171116117\n",
      "Pearson r: 0.921\n",
      "Validation loss: 0.25978517532348633\n",
      "Best Pearson r: 0.921\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 3.496664995842792\n",
      "Pearson r: 0.883\n",
      "Validation loss: 0.35955649614334106\n",
      "Best Pearson r: 0.883\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3093435510675957\n",
      "Pearson r: 0.883\n",
      "Validation loss: 0.3615487515926361\n",
      "Best Pearson r: 0.883\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.269563890518026\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.31541505455970764\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.843995787995927\n",
      "Pearson r: 0.92\n",
      "Validation loss: 0.2545391023159027\n",
      "Best Pearson r: 0.92\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.432030181935493\n",
      "Pearson r: 0.92\n",
      "Validation loss: 0.2511308193206787\n",
      "Best Pearson r: 0.92\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 2.2420481177086526\n",
      "Pearson r: 0.923\n",
      "Validation loss: 0.24294696748256683\n",
      "Best Pearson r: 0.923\n",
      "\n",
      "Epoch: 8\n",
      "Train loss: 2.0369908790639104\n",
      "Pearson r: 0.92\n",
      "Validation loss: 0.2527743875980377\n",
      "Best Pearson r: 0.923\n",
      "\n",
      "Epoch: 9\n",
      "Train loss: 1.8677998965090894\n",
      "Pearson r: 0.922\n",
      "Validation loss: 0.2433396577835083\n",
      "Best Pearson r: 0.923\n",
      "\n",
      "Epoch: 10\n",
      "Train loss: 1.7224931399872963\n",
      "Pearson r: 0.918\n",
      "Validation loss: 0.2741895318031311\n",
      "\n",
      "----Pearson r: 0.923----\n",
      "\n",
      "Fold: 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 16.92278828519456\n",
      "Pearson r: 0.901\n",
      "Validation loss: 0.3265203833580017\n",
      "Best Pearson r: 0.901\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 4.004501048554766\n",
      "Pearson r: 0.891\n",
      "Validation loss: 0.4479040503501892\n",
      "Best Pearson r: 0.901\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.5454871045782212\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.39590683579444885\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.246302886212126\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.3832874298095703\n",
      "\n",
      "----Pearson r: 0.902----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 18.10117255119567\n",
      "Pearson r: 0.901\n",
      "Validation loss: 0.3370157778263092\n",
      "Best Pearson r: 0.901\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 4.061595972548139\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.40321534872055054\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.611900030298436\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.4078496992588043\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.813951335054763\n",
      "Pearson r: 0.9\n",
      "Validation loss: 0.42866846919059753\n",
      "\n",
      "----Pearson r: 0.902----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 17.55196452140808\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.32056644558906555\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.843478740529811\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.373733788728714\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.498464910273856\n",
      "Pearson r: 0.905\n",
      "Validation loss: 0.3123871982097626\n",
      "Best Pearson r: 0.905\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.5134388702981014\n",
      "Pearson r: 0.901\n",
      "Validation loss: 0.505249559879303\n",
      "\n",
      "----Pearson r: 0.905----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 15.651401428466148\n",
      "Pearson r: 0.86\n",
      "Validation loss: 0.418253093957901\n",
      "Best Pearson r: 0.86\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.736322522163391\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.3705071806907654\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.409765380494138\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.39554691314697266\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.7552242773644466\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.48315468430519104\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.0286416024603744\n",
      "Pearson r: 0.886\n",
      "Validation loss: 0.4723425805568695\n",
      "\n",
      "----Pearson r: 0.902----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 15.133260777656067\n",
      "Pearson r: -0.108\n",
      "Validation loss: 640.6860961914062\n",
      "Best Pearson r: -0.108\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.5168038467143443\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.36452409625053406\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.170403131779204\n",
      "Pearson r: 0.904\n",
      "Validation loss: 0.37495654821395874\n",
      "Best Pearson r: 0.904\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.236132874133739\n",
      "Pearson r: 0.897\n",
      "Validation loss: 0.44887372851371765\n",
      "Best Pearson r: 0.904\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 1.7294478559113564\n",
      "Pearson r: 0.897\n",
      "Validation loss: 0.4512709081172943\n",
      "\n",
      "----Pearson r: 0.904----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 14.128800275477957\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.320317804813385\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.710733971697219\n",
      "Pearson r: 0.901\n",
      "Validation loss: 0.33264487981796265\n",
      "Best Pearson r: 0.901\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3318988224293324\n",
      "Pearson r: 0.905\n",
      "Validation loss: 0.33948394656181335\n",
      "Best Pearson r: 0.905\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.5050586404952595\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.36526554822921753\n",
      "\n",
      "----Pearson r: 0.905----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 14.688132930309214\n",
      "Pearson r: 0.901\n",
      "Validation loss: 0.3256511092185974\n",
      "Best Pearson r: 0.901\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.5560956971442446\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.3311008810997009\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3812453594613583\n",
      "Pearson r: 0.903\n",
      "Validation loss: 0.32297900319099426\n",
      "Best Pearson r: 0.903\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.84496353534942\n",
      "Pearson r: 0.897\n",
      "Validation loss: 0.3501777648925781\n",
      "\n",
      "----Pearson r: 0.903----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 13.445453532198643\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.323919415473938\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.644290721162837\n",
      "Pearson r: 0.901\n",
      "Validation loss: 0.32096099853515625\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.5164513486496944\n",
      "Pearson r: 0.903\n",
      "Validation loss: 0.30494269728660583\n",
      "Best Pearson r: 0.903\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.436575693018893\n",
      "Pearson r: 0.906\n",
      "Validation loss: 0.31000304222106934\n",
      "Best Pearson r: 0.906\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.8731494545936584\n",
      "Pearson r: 0.905\n",
      "Validation loss: 0.29766035079956055\n",
      "Best Pearson r: 0.906\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.4038196244138352\n",
      "Pearson r: 0.901\n",
      "Validation loss: 0.3832120895385742\n",
      "\n",
      "----Pearson r: 0.906----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 13.49400834834322\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.3196958899497986\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.5816136623950716\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.30817049741744995\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3691229604660196\n",
      "Pearson r: 0.903\n",
      "Validation loss: 0.3181349039077759\n",
      "Best Pearson r: 0.903\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.8330584257207017\n",
      "Pearson r: 0.901\n",
      "Validation loss: 0.3205200135707855\n",
      "Best Pearson r: 0.903\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.4313781933581575\n",
      "Pearson r: 0.05\n",
      "Validation loss: 126.50206756591797\n",
      "\n",
      "----Pearson r: 0.903----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 13.181365180522837\n",
      "Pearson r: 0.901\n",
      "Validation loss: 0.3506004214286804\n",
      "Best Pearson r: 0.901\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.528872824729757\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.31368979811668396\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3919899653881154\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.30343976616859436\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.3747295090492737\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.3031698763370514\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 3.3614522738659636\n",
      "Pearson r: 0.371\n",
      "Validation loss: 5.712167739868164\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.8775748724633075\n",
      "Pearson r: 0.906\n",
      "Validation loss: 0.2873850166797638\n",
      "Best Pearson r: 0.906\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 2.608219529720063\n",
      "Pearson r: 0.357\n",
      "Validation loss: 5.636375904083252\n",
      "Best Pearson r: 0.906\n",
      "\n",
      "Epoch: 8\n",
      "Train loss: 2.3342173207313457\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.31925177574157715\n",
      "Best Pearson r: 0.906\n",
      "\n",
      "Epoch: 9\n",
      "Train loss: 2.2164892021645892\n",
      "Pearson r: 0.897\n",
      "Validation loss: 0.31447717547416687\n",
      "\n",
      "----Pearson r: 0.906----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 12.193808563212132\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.32267048954963684\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.470005526187572\n",
      "Pearson r: 0.778\n",
      "Validation loss: 0.7646541595458984\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.320723688348811\n",
      "Pearson r: 0.906\n",
      "Validation loss: 0.2916536033153534\n",
      "Best Pearson r: 0.906\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.013138910557361\n",
      "Pearson r: 0.399\n",
      "Validation loss: 5.634988307952881\n",
      "Best Pearson r: 0.906\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.694628634351365\n",
      "Pearson r: 0.893\n",
      "Validation loss: 0.33927831053733826\n",
      "Best Pearson r: 0.906\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.343507097756609\n",
      "Pearson r: 0.9\n",
      "Validation loss: 0.29416996240615845\n",
      "\n",
      "----Pearson r: 0.906----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 11.558222986282185\n",
      "Pearson r: 0.901\n",
      "Validation loss: 0.3475556969642639\n",
      "Best Pearson r: 0.901\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.5262950506616146\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.2922227084636688\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3309488867191557\n",
      "Pearson r: 0.904\n",
      "Validation loss: 0.29131612181663513\n",
      "Best Pearson r: 0.904\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.084764121694768\n",
      "Pearson r: 0.903\n",
      "Validation loss: 0.2939341366291046\n",
      "Best Pearson r: 0.904\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.688891478041385\n",
      "Pearson r: 0.903\n",
      "Validation loss: 0.2851516902446747\n",
      "\n",
      "----Pearson r: 0.904----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 11.77334532331913\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.3355158567428589\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.4527374125541526\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.2969076335430145\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.4164316616159804\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.3212006986141205\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.4313476592936416\n",
      "Pearson r: 0.013\n",
      "Validation loss: 161.36920166015625\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 3.148491082039285\n",
      "Pearson r: 0.907\n",
      "Validation loss: 0.29253873229026794\n",
      "\n",
      "----Pearson r: 0.907----\n",
      "\n",
      "Fold: 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 17.35443751355435\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.41756945848464966\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 4.117270236319684\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.39024803042411804\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.611266406292611\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.3940421938896179\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.640510292763406\n",
      "Pearson r: 0.903\n",
      "Validation loss: 0.40187737345695496\n",
      "Best Pearson r: 0.903\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 1.8566075531726187\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.4348807632923126\n",
      "\n",
      "----Pearson r: 0.903----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 17.24581307045957\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.37546998262405396\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.9879539038272616\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.4013703763484955\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3021116840078477\n",
      "Pearson r: 0.797\n",
      "Validation loss: 0.977020800113678\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.2587428232456777\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.5327920913696289\n",
      "\n",
      "----Pearson r: 0.899----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 16.795881590944656\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.38221991062164307\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.8965179894832853\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.3850806951522827\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.2998690224708396\n",
      "Pearson r: 0.905\n",
      "Validation loss: 0.38340601325035095\n",
      "Best Pearson r: 0.905\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.216701784666548\n",
      "Pearson r: 0.903\n",
      "Validation loss: 0.4893134832382202\n",
      "\n",
      "----Pearson r: 0.905----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 16.17490269275422\n",
      "Pearson r: 0.897\n",
      "Validation loss: 0.3667958378791809\n",
      "Best Pearson r: 0.897\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.627269722045736\n",
      "Pearson r: 0.891\n",
      "Validation loss: 0.41019320487976074\n",
      "Best Pearson r: 0.897\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.147824487787612\n",
      "Pearson r: 0.904\n",
      "Validation loss: 0.3651158809661865\n",
      "Best Pearson r: 0.904\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.1607945041453585\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.403887540102005\n",
      "\n",
      "----Pearson r: 0.904----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 15.964157809602453\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.397963285446167\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.6370568972952824\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.3609803318977356\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 2.9018388428586595\n",
      "Pearson r: 0.908\n",
      "Validation loss: 0.312523752450943\n",
      "Best Pearson r: 0.908\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.184029683787772\n",
      "Pearson r: 0.906\n",
      "Validation loss: 0.3784591853618622\n",
      "Best Pearson r: 0.908\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 1.7682528695527544\n",
      "Pearson r: 0.904\n",
      "Validation loss: 0.35815152525901794\n",
      "Best Pearson r: 0.908\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 1.455457552950433\n",
      "Pearson r: 0.11\n",
      "Validation loss: 66.09710693359375\n",
      "\n",
      "----Pearson r: 0.908----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 15.130991905293566\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.3794301152229309\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.6995222352920694\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.3570687174797058\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3993018320266235\n",
      "Pearson r: 0.91\n",
      "Validation loss: 0.3065339922904968\n",
      "Best Pearson r: 0.91\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.52076999177324\n",
      "Pearson r: 0.912\n",
      "Validation loss: 0.3321949243545532\n",
      "Best Pearson r: 0.912\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 1.9947237226557224\n",
      "Pearson r: 0.907\n",
      "Validation loss: 0.3727080821990967\n",
      "Best Pearson r: 0.912\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 1.6232978029454008\n",
      "Pearson r: 0.909\n",
      "Validation loss: 0.39413100481033325\n",
      "\n",
      "----Pearson r: 0.912----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 13.821878620918762\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.39007502794265747\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.537564853404431\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.325967013835907\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.36664968348564\n",
      "Pearson r: 0.901\n",
      "Validation loss: 0.33098751306533813\n",
      "Best Pearson r: 0.902\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.9800228032659977\n",
      "Pearson r: 0.909\n",
      "Validation loss: 0.3307413160800934\n",
      "Best Pearson r: 0.909\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.5876421294313796\n",
      "Pearson r: 0.903\n",
      "Validation loss: 0.41371792554855347\n",
      "\n",
      "----Pearson r: 0.909----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 13.170200358045863\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.38260403275489807\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.636575252451795\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.3373584747314453\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.480806161748602\n",
      "Pearson r: 0.901\n",
      "Validation loss: 0.32335129380226135\n",
      "Best Pearson r: 0.901\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.9769354272396007\n",
      "Pearson r: 0.91\n",
      "Validation loss: 0.31930142641067505\n",
      "Best Pearson r: 0.91\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.529427669149764\n",
      "Pearson r: 0.912\n",
      "Validation loss: 0.31685999035835266\n",
      "Best Pearson r: 0.912\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.145837386871906\n",
      "Pearson r: 0.908\n",
      "Validation loss: 0.3847602307796478\n",
      "\n",
      "----Pearson r: 0.912----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 13.053194355457387\n",
      "Pearson r: 0.878\n",
      "Validation loss: 0.46754124760627747\n",
      "Best Pearson r: 0.878\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.5289419889450073\n",
      "Pearson r: -0.081\n",
      "Validation loss: 442.2768249511719\n",
      "Best Pearson r: 0.878\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.419018339603505\n",
      "Pearson r: 0.893\n",
      "Validation loss: 0.35742467641830444\n",
      "Best Pearson r: 0.893\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.245365901196257\n",
      "Pearson r: 0.908\n",
      "Validation loss: 0.3105538487434387\n",
      "Best Pearson r: 0.908\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.7338799669387495\n",
      "Pearson r: 0.917\n",
      "Validation loss: 0.281470388174057\n",
      "Best Pearson r: 0.917\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.343845927968938\n",
      "Pearson r: 0.915\n",
      "Validation loss: 0.3014165461063385\n",
      "Best Pearson r: 0.917\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 2.0605114704750953\n",
      "Pearson r: 0.916\n",
      "Validation loss: 0.31195032596588135\n",
      "Best Pearson r: 0.917\n",
      "\n",
      "Epoch: 8\n",
      "Train loss: 1.8612705329631238\n",
      "Pearson r: 0.917\n",
      "Validation loss: 0.2985796630382538\n",
      "\n",
      "----Pearson r: 0.917----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 12.244167305053548\n",
      "Pearson r: 0.898\n",
      "Validation loss: 0.3737782835960388\n",
      "Best Pearson r: 0.898\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.386688694040826\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.3318626582622528\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.223323076329333\n",
      "Pearson r: 0.918\n",
      "Validation loss: 0.2710355222225189\n",
      "Best Pearson r: 0.918\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.7526667561936886\n",
      "Pearson r: 0.105\n",
      "Validation loss: 53.40520095825195\n",
      "Best Pearson r: 0.918\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.4544636448647115\n",
      "Pearson r: 0.907\n",
      "Validation loss: 0.3187784254550934\n",
      "Best Pearson r: 0.918\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.083658459338736\n",
      "Pearson r: 0.921\n",
      "Validation loss: 0.27957624197006226\n",
      "\n",
      "----Pearson r: 0.921----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 12.389487063631098\n",
      "Pearson r: 0.897\n",
      "Validation loss: 0.42129236459732056\n",
      "Best Pearson r: 0.897\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.4322462500409876\n",
      "Pearson r: 0.9\n",
      "Validation loss: 0.3292304277420044\n",
      "Best Pearson r: 0.9\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3376828761810953\n",
      "Pearson r: 0.9\n",
      "Validation loss: 0.32812607288360596\n",
      "Best Pearson r: 0.9\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.0474808571186474\n",
      "Pearson r: 0.915\n",
      "Validation loss: 0.28532522916793823\n",
      "Best Pearson r: 0.915\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.6334822177886963\n",
      "Pearson r: 0.916\n",
      "Validation loss: 0.29448965191841125\n",
      "Best Pearson r: 0.916\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.4498935988608825\n",
      "Pearson r: 0.918\n",
      "Validation loss: 0.2673458755016327\n",
      "Best Pearson r: 0.918\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 2.1544562597224055\n",
      "Pearson r: 0.921\n",
      "Validation loss: 0.2718620300292969\n",
      "Best Pearson r: 0.921\n",
      "\n",
      "Epoch: 8\n",
      "Train loss: 1.9099621601561283\n",
      "Pearson r: 0.916\n",
      "Validation loss: 0.28189995884895325\n",
      "Best Pearson r: 0.921\n",
      "\n",
      "Epoch: 9\n",
      "Train loss: 1.6526142003688407\n",
      "Pearson r: 0.912\n",
      "Validation loss: 0.3113270401954651\n",
      "\n",
      "----Pearson r: 0.921----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 11.90965703954088\n",
      "Pearson r: 0.709\n",
      "Validation loss: 0.8767975568771362\n",
      "Best Pearson r: 0.709\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.4052747018793794\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.33100733160972595\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3515444106244026\n",
      "Pearson r: 0.904\n",
      "Validation loss: 0.3156275153160095\n",
      "Best Pearson r: 0.904\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.897906072596286\n",
      "Pearson r: 0.917\n",
      "Validation loss: 0.29107123613357544\n",
      "Best Pearson r: 0.917\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.659290624425766\n",
      "Pearson r: 0.916\n",
      "Validation loss: 0.29283952713012695\n",
      "Best Pearson r: 0.917\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.2320964209576872\n",
      "Pearson r: 0.912\n",
      "Validation loss: 0.30198800563812256\n",
      "Best Pearson r: 0.917\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 2.0044073842941446\n",
      "Pearson r: 0.917\n",
      "Validation loss: 0.2722495198249817\n",
      "Best Pearson r: 0.917\n",
      "\n",
      "Epoch: 8\n",
      "Train loss: 1.780952200610587\n",
      "Pearson r: 0.918\n",
      "Validation loss: 0.27238842844963074\n",
      "Best Pearson r: 0.918\n",
      "\n",
      "Epoch: 9\n",
      "Train loss: 1.6005696207284927\n",
      "Pearson r: 0.908\n",
      "Validation loss: 0.3050535321235657\n",
      "Best Pearson r: 0.918\n",
      "\n",
      "Epoch: 10\n",
      "Train loss: 1.449971505936156\n",
      "Pearson r: 0.905\n",
      "Validation loss: 0.3127261698246002\n",
      "\n",
      "----Pearson r: 0.918----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 11.35284111854878\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.39557257294654846\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.429415297000966\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.33031412959098816\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.310208850718559\n",
      "Pearson r: 0.069\n",
      "Validation loss: 70.92578125\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.8501457305664712\n",
      "Pearson r: 0.913\n",
      "Validation loss: 0.2954516112804413\n",
      "Best Pearson r: 0.913\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.7313495944155024\n",
      "Pearson r: -0.098\n",
      "Validation loss: 561.1358642578125\n",
      "Best Pearson r: 0.913\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.345865937623572\n",
      "Pearson r: 0.905\n",
      "Validation loss: 0.3341723084449768\n",
      "Best Pearson r: 0.913\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 2.138645886740786\n",
      "Pearson r: 0.914\n",
      "Validation loss: 0.2924008369445801\n",
      "\n",
      "----Pearson r: 0.914----\n",
      "\n",
      "Fold: 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 17.332630299507304\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.33586016297340393\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.982367468641159\n",
      "Pearson r: 0.808\n",
      "Validation loss: 0.8843473792076111\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.444778434773709\n",
      "Pearson r: 0.064\n",
      "Validation loss: inf\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.227932108209488\n",
      "Pearson r: 0.908\n",
      "Validation loss: 0.4898177981376648\n",
      "\n",
      "----Pearson r: 0.908----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 17.51433592654289\n",
      "Pearson r: 0.847\n",
      "Validation loss: 0.4651355445384979\n",
      "Best Pearson r: 0.847\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 4.029567371023462\n",
      "Pearson r: 0.061\n",
      "Validation loss: 113.72669219970703\n",
      "Best Pearson r: 0.847\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.4774723484161054\n",
      "Pearson r: 0.91\n",
      "Validation loss: 0.33897730708122253\n",
      "Best Pearson r: 0.91\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.3630709495950253\n",
      "Pearson r: 0.907\n",
      "Validation loss: 0.41973936557769775\n",
      "Best Pearson r: 0.91\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 1.7166665893919923\n",
      "Pearson r: 0.902\n",
      "Validation loss: 0.3968159854412079\n",
      "Best Pearson r: 0.91\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 1.4058875913949722\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.4414554536342621\n",
      "\n",
      "----Pearson r: 0.91----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 17.505545895150366\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.353274405002594\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 4.028392160192449\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.3795022964477539\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.2310383446673128\n",
      "Pearson r: 0.91\n",
      "Validation loss: 0.3335613012313843\n",
      "Best Pearson r: 0.91\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.1502875311577574\n",
      "Pearson r: 0.905\n",
      "Validation loss: 0.48193979263305664\n",
      "Best Pearson r: 0.91\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 1.578029401124792\n",
      "Pearson r: 0.905\n",
      "Validation loss: 0.3978419899940491\n",
      "Best Pearson r: 0.91\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 1.2243922993223717\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.45646217465400696\n",
      "\n",
      "----Pearson r: 0.91----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 16.798595190048218\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.3432597517967224\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.7449788438512925\n",
      "Pearson r: 0.813\n",
      "Validation loss: 0.8400395512580872\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.1786274377335895\n",
      "Pearson r: 0.907\n",
      "Validation loss: 0.3828127980232239\n",
      "Best Pearson r: 0.907\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.160457373933589\n",
      "Pearson r: 0.906\n",
      "Validation loss: 0.4650743007659912\n",
      "\n",
      "----Pearson r: 0.907----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 15.138721836374161\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.33194229006767273\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.586125759368247\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.37952420115470886\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.282450184543082\n",
      "Pearson r: 0.9\n",
      "Validation loss: 0.35983550548553467\n",
      "Best Pearson r: 0.9\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.813083415335797\n",
      "Pearson r: 0.9\n",
      "Validation loss: 0.4174386262893677\n",
      "\n",
      "----Pearson r: 0.9----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 15.174600535250725\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.354055792093277\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.7165957765376314\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.3540329933166504\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.4340185890806483\n",
      "Pearson r: 0.905\n",
      "Validation loss: 0.3224804997444153\n",
      "Best Pearson r: 0.905\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.7239515984312015\n",
      "Pearson r: 0.071\n",
      "Validation loss: 75.90435791015625\n",
      "Best Pearson r: 0.905\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.087325202023729\n",
      "Pearson r: 0.906\n",
      "Validation loss: 0.4125922918319702\n",
      "Best Pearson r: 0.906\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 1.8371319504494363\n",
      "Pearson r: 0.9\n",
      "Validation loss: 0.32725849747657776\n",
      "\n",
      "----Pearson r: 0.906----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 14.170855372510058\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.34136730432510376\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.5512313918864473\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.32296353578567505\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.362204812942667\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.3541173040866852\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.0958584356815257\n",
      "Pearson r: 0.907\n",
      "Validation loss: 0.338996946811676\n",
      "Best Pearson r: 0.907\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.2932496419612396\n",
      "Pearson r: 0.908\n",
      "Validation loss: 0.33882811665534973\n",
      "\n",
      "----Pearson r: 0.908----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 13.70884179815333\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.34062090516090393\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.608099269106033\n",
      "Pearson r: 0.9\n",
      "Validation loss: 0.31689709424972534\n",
      "Best Pearson r: 0.9\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.4322178617436836\n",
      "Pearson r: 0.91\n",
      "Validation loss: 0.27816227078437805\n",
      "Best Pearson r: 0.91\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.7296297734088086\n",
      "Pearson r: 0.906\n",
      "Validation loss: 0.33062466979026794\n",
      "Best Pearson r: 0.91\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.360290157668134\n",
      "Pearson r: 0.911\n",
      "Validation loss: 0.31484612822532654\n",
      "Best Pearson r: 0.911\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.201380881223273\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.3718009889125824\n",
      "\n",
      "----Pearson r: 0.911----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 13.550270671540119\n",
      "Pearson r: 0.072\n",
      "Validation loss: 40.93603515625\n",
      "Best Pearson r: 0.072\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.6206570331086505\n",
      "Pearson r: 0.891\n",
      "Validation loss: 0.3471498489379883\n",
      "Best Pearson r: 0.891\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.416126360284521\n",
      "Pearson r: 0.083\n",
      "Validation loss: 65.99078369140625\n",
      "Best Pearson r: 0.891\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.152352125086683\n",
      "Pearson r: 0.914\n",
      "Validation loss: 0.2617742717266083\n",
      "Best Pearson r: 0.914\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.7963149293940117\n",
      "Pearson r: 0.916\n",
      "Validation loss: 0.264102578163147\n",
      "Best Pearson r: 0.916\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.5165249172677386\n",
      "Pearson r: 0.906\n",
      "Validation loss: 0.32266196608543396\n",
      "Best Pearson r: 0.916\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 2.1828824624102166\n",
      "Pearson r: 0.904\n",
      "Validation loss: 0.29177260398864746\n",
      "\n",
      "----Pearson r: 0.916----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 12.469989284555963\n",
      "Pearson r: 0.02\n",
      "Validation loss: 121.20925903320312\n",
      "Best Pearson r: 0.02\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.4470097168963005\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.31999146938323975\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3179150566141655\n",
      "Pearson r: 0.898\n",
      "Validation loss: 0.31469517946243286\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.9196893686943866\n",
      "Pearson r: 0.915\n",
      "Validation loss: 0.268283873796463\n",
      "Best Pearson r: 0.915\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.53067036765687\n",
      "Pearson r: 0.911\n",
      "Validation loss: 0.2729792892932892\n",
      "Best Pearson r: 0.915\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.2066497060846775\n",
      "Pearson r: 0.906\n",
      "Validation loss: 0.28656935691833496\n",
      "Best Pearson r: 0.915\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 1.926980031297562\n",
      "Pearson r: 0.911\n",
      "Validation loss: 0.30963054299354553\n",
      "\n",
      "----Pearson r: 0.915----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 13.085600746438859\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.3594644069671631\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.457332373933589\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.31350722908973694\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.279574825408611\n",
      "Pearson r: 0.9\n",
      "Validation loss: 0.3316578269004822\n",
      "Best Pearson r: 0.9\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.0527137378428844\n",
      "Pearson r: 0.914\n",
      "Validation loss: 0.26597049832344055\n",
      "Best Pearson r: 0.914\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.586540075692725\n",
      "Pearson r: 0.915\n",
      "Validation loss: 0.2836591899394989\n",
      "Best Pearson r: 0.915\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.270404115636298\n",
      "Pearson r: 0.913\n",
      "Validation loss: 0.2966548204421997\n",
      "Best Pearson r: 0.915\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 2.081480932996628\n",
      "Pearson r: 0.908\n",
      "Validation loss: 0.33256834745407104\n",
      "\n",
      "----Pearson r: 0.915----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 11.749723386257253\n",
      "Pearson r: 0.898\n",
      "Validation loss: 0.3703416883945465\n",
      "Best Pearson r: 0.898\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.4684257963870433\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.3088728189468384\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.4126538444072643\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.30855125188827515\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.433063138038554\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.30766838788986206\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 3.3912738079720355\n",
      "Pearson r: 0.9\n",
      "Validation loss: 0.30791574716567993\n",
      "\n",
      "----Pearson r: 0.9----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 11.933624896597355\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.385136216878891\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.528157005918787\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.30504631996154785\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.424364977694572\n",
      "Pearson r: 0.9\n",
      "Validation loss: 0.30404403805732727\n",
      "Best Pearson r: 0.9\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.300803149000127\n",
      "Pearson r: 0.915\n",
      "Validation loss: 0.2603577971458435\n",
      "Best Pearson r: 0.915\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.8931075778413327\n",
      "Pearson r: 0.915\n",
      "Validation loss: 0.2656513452529907\n",
      "Best Pearson r: 0.915\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.558257002779778\n",
      "Pearson r: 0.918\n",
      "Validation loss: 0.2544896602630615\n",
      "Best Pearson r: 0.918\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 2.3247629397727074\n",
      "Pearson r: 0.915\n",
      "Validation loss: 0.2581748366355896\n",
      "\n",
      "----Pearson r: 0.918----\n",
      "\n",
      "Fold: 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 18.01349094066214\n",
      "Pearson r: 0.873\n",
      "Validation loss: 0.3615938425064087\n",
      "Best Pearson r: 0.873\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 4.027583621917887\n",
      "Pearson r: 0.874\n",
      "Validation loss: 0.5132996439933777\n",
      "Best Pearson r: 0.874\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.2665141161451947\n",
      "Pearson r: 0.879\n",
      "Validation loss: 0.393028199672699\n",
      "Best Pearson r: 0.879\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.285768285710761\n",
      "Pearson r: 0.88\n",
      "Validation loss: 0.6223498582839966\n",
      "\n",
      "----Pearson r: 0.88----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 17.17024465317422\n",
      "Pearson r: 0.861\n",
      "Validation loss: 0.3766971528530121\n",
      "Best Pearson r: 0.861\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.830173281913108\n",
      "Pearson r: 0.874\n",
      "Validation loss: 0.4726026952266693\n",
      "Best Pearson r: 0.874\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.239134041552848\n",
      "Pearson r: 0.883\n",
      "Validation loss: 0.580225944519043\n",
      "Best Pearson r: 0.883\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.344824253244603\n",
      "Pearson r: 0.878\n",
      "Validation loss: 0.5085448026657104\n",
      "\n",
      "----Pearson r: 0.883----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 15.799715531633256\n",
      "Pearson r: 0.874\n",
      "Validation loss: 0.3417792320251465\n",
      "Best Pearson r: 0.874\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.573654392932324\n",
      "Pearson r: 0.874\n",
      "Validation loss: 0.5062392354011536\n",
      "Best Pearson r: 0.874\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.4141109763307775\n",
      "Pearson r: 0.095\n",
      "Validation loss: 66.03777313232422\n",
      "Best Pearson r: 0.874\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.374318075306872\n",
      "Pearson r: 0.88\n",
      "Validation loss: 0.4602760970592499\n",
      "\n",
      "----Pearson r: 0.88----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 15.735175041442222\n",
      "Pearson r: 0.874\n",
      "Validation loss: 0.3443043529987335\n",
      "Best Pearson r: 0.874\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.58074382137745\n",
      "Pearson r: 0.874\n",
      "Validation loss: 0.47039875388145447\n",
      "Best Pearson r: 0.874\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3076405258888895\n",
      "Pearson r: 0.875\n",
      "Validation loss: 0.48462894558906555\n",
      "Best Pearson r: 0.875\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.3719394707933383\n",
      "Pearson r: 0.887\n",
      "Validation loss: 0.5088616013526917\n",
      "\n",
      "----Pearson r: 0.887----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 16.156870063315047\n",
      "Pearson r: 0.873\n",
      "Validation loss: 0.3546964228153229\n",
      "Best Pearson r: 0.873\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.5349435235591646\n",
      "Pearson r: 0.874\n",
      "Validation loss: 0.47267648577690125\n",
      "Best Pearson r: 0.874\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.2687864506498294\n",
      "Pearson r: 0.875\n",
      "Validation loss: 0.4696650207042694\n",
      "Best Pearson r: 0.875\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.718167339233642\n",
      "Pearson r: 0.883\n",
      "Validation loss: 0.5357332825660706\n",
      "\n",
      "----Pearson r: 0.883----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 14.869501859583753\n",
      "Pearson r: 0.825\n",
      "Validation loss: 0.4628797769546509\n",
      "Best Pearson r: 0.825\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.7286536414572535\n",
      "Pearson r: 0.232\n",
      "Validation loss: 15.727113723754883\n",
      "Best Pearson r: 0.825\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.242069779558385\n",
      "Pearson r: 0.888\n",
      "Validation loss: 0.3744627833366394\n",
      "Best Pearson r: 0.888\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.3738050143769445\n",
      "Pearson r: 0.874\n",
      "Validation loss: 0.4179706573486328\n",
      "Best Pearson r: 0.888\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 1.8724291781161695\n",
      "Pearson r: 0.875\n",
      "Validation loss: 0.38687312602996826\n",
      "Best Pearson r: 0.888\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 1.5462363669846921\n",
      "Pearson r: 0.88\n",
      "Validation loss: 0.47640955448150635\n",
      "\n",
      "----Pearson r: 0.888----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 15.471684816035818\n",
      "Pearson r: 0.874\n",
      "Validation loss: 0.38042521476745605\n",
      "Best Pearson r: 0.874\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.673088664704181\n",
      "Pearson r: 0.13\n",
      "Validation loss: 40.866416931152344\n",
      "Best Pearson r: 0.874\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.2753353993943395\n",
      "Pearson r: 0.886\n",
      "Validation loss: 0.3249325752258301\n",
      "Best Pearson r: 0.886\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.6957623070858894\n",
      "Pearson r: 0.887\n",
      "Validation loss: 0.39708516001701355\n",
      "Best Pearson r: 0.887\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.292532153586124\n",
      "Pearson r: 0.874\n",
      "Validation loss: 0.4171753525733948\n",
      "Best Pearson r: 0.887\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 1.9987830532358049\n",
      "Pearson r: 0.889\n",
      "Validation loss: 0.39303717017173767\n",
      "\n",
      "----Pearson r: 0.889----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 13.795694127995917\n",
      "Pearson r: 0.03\n",
      "Validation loss: 91.02588653564453\n",
      "Best Pearson r: 0.03\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.585168272890943\n",
      "Pearson r: 0.874\n",
      "Validation loss: 0.38527828454971313\n",
      "Best Pearson r: 0.874\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.347338998571355\n",
      "Pearson r: 0.881\n",
      "Validation loss: 0.3749743402004242\n",
      "Best Pearson r: 0.881\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.791570469420007\n",
      "Pearson r: 0.89\n",
      "Validation loss: 0.34711772203445435\n",
      "Best Pearson r: 0.89\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.3708084314427476\n",
      "Pearson r: 0.889\n",
      "Validation loss: 0.405048668384552\n",
      "Best Pearson r: 0.89\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.1197238900560014\n",
      "Pearson r: 0.884\n",
      "Validation loss: 0.4064400792121887\n",
      "Best Pearson r: 0.89\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 1.7947544404800901\n",
      "Pearson r: 0.88\n",
      "Validation loss: 0.3859800696372986\n",
      "\n",
      "----Pearson r: 0.89----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 13.301077272029634\n",
      "Pearson r: 0.873\n",
      "Validation loss: 0.3574490249156952\n",
      "Best Pearson r: 0.873\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.512804041517542\n",
      "Pearson r: 0.873\n",
      "Validation loss: 0.3721201419830322\n",
      "Best Pearson r: 0.873\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3712987024733363\n",
      "Pearson r: 0.876\n",
      "Validation loss: 0.3711271584033966\n",
      "Best Pearson r: 0.876\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.9338753426328616\n",
      "Pearson r: 0.887\n",
      "Validation loss: 0.3190005421638489\n",
      "Best Pearson r: 0.887\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.4275414271557585\n",
      "Pearson r: 0.883\n",
      "Validation loss: 0.3672698438167572\n",
      "Best Pearson r: 0.887\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.1334315994952586\n",
      "Pearson r: 0.883\n",
      "Validation loss: 0.3475242257118225\n",
      "Best Pearson r: 0.887\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 1.8555415380508342\n",
      "Pearson r: 0.848\n",
      "Validation loss: 0.47333669662475586\n",
      "\n",
      "----Pearson r: 0.887----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 12.76446260289943\n",
      "Pearson r: 0.698\n",
      "Validation loss: 0.810617208480835\n",
      "Best Pearson r: 0.698\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.4549433842618416\n",
      "Pearson r: 0.874\n",
      "Validation loss: 0.37994077801704407\n",
      "Best Pearson r: 0.874\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.2990010203199183\n",
      "Pearson r: 0.876\n",
      "Validation loss: 0.3434945344924927\n",
      "Best Pearson r: 0.876\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.27166644499657\n",
      "Pearson r: 0.877\n",
      "Validation loss: 0.3637698292732239\n",
      "Best Pearson r: 0.877\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 3.027943287758117\n",
      "Pearson r: 0.867\n",
      "Validation loss: 0.46978679299354553\n",
      "Best Pearson r: 0.877\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.6372286677360535\n",
      "Pearson r: 0.886\n",
      "Validation loss: 0.31488507986068726\n",
      "Best Pearson r: 0.886\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 2.3489363092057247\n",
      "Pearson r: 0.887\n",
      "Validation loss: 0.3370720148086548\n",
      "Best Pearson r: 0.887\n",
      "\n",
      "Epoch: 8\n",
      "Train loss: 2.1638755265702594\n",
      "Pearson r: 0.888\n",
      "Validation loss: 0.34526801109313965\n",
      "Best Pearson r: 0.888\n",
      "\n",
      "Epoch: 9\n",
      "Train loss: 1.9976074961905783\n",
      "Pearson r: 0.877\n",
      "Validation loss: 0.36441075801849365\n",
      "\n",
      "----Pearson r: 0.888----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 12.469064418305742\n",
      "Pearson r: 0.872\n",
      "Validation loss: 0.36246755719184875\n",
      "Best Pearson r: 0.872\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.450895530112246\n",
      "Pearson r: 0.874\n",
      "Validation loss: 0.37363144755363464\n",
      "Best Pearson r: 0.874\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.3167530450415104\n",
      "Pearson r: 0.874\n",
      "Validation loss: 0.3706496059894562\n",
      "Best Pearson r: 0.874\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.315901022008125\n",
      "Pearson r: 0.874\n",
      "Validation loss: 0.3987455666065216\n",
      "\n",
      "----Pearson r: 0.874----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 11.588499340605228\n",
      "Pearson r: 0.874\n",
      "Validation loss: 0.3484444320201874\n",
      "Best Pearson r: 0.874\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.4113551428977478\n",
      "Pearson r: 0.874\n",
      "Validation loss: 0.3643069565296173\n",
      "Best Pearson r: 0.874\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.250780796751063\n",
      "Pearson r: 0.893\n",
      "Validation loss: 0.29399076104164124\n",
      "Best Pearson r: 0.893\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 2.77553114358415\n",
      "Pearson r: 0.894\n",
      "Validation loss: 0.3357246220111847\n",
      "Best Pearson r: 0.894\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.419114201626879\n",
      "Pearson r: 0.899\n",
      "Validation loss: 0.299678772687912\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.1241658114372415\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.2834005653858185\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 1.8762602806091309\n",
      "Pearson r: 0.894\n",
      "Validation loss: 0.30081892013549805\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 8\n",
      "Train loss: 1.6131584701385904\n",
      "Pearson r: 0.891\n",
      "Validation loss: 0.33059629797935486\n",
      "Best Pearson r: 0.899\n",
      "\n",
      "Epoch: 9\n",
      "Train loss: 1.4682482205172802\n",
      "Pearson r: 0.885\n",
      "Validation loss: 0.3406224548816681\n",
      "\n",
      "----Pearson r: 0.899----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 11.769449807227925\n",
      "Pearson r: 0.873\n",
      "Validation loss: 0.36714956164360046\n",
      "Best Pearson r: 0.873\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.541997215849288\n",
      "Pearson r: -0.017\n",
      "Validation loss: 216.5758056640625\n",
      "Best Pearson r: 0.873\n",
      "\n",
      "Epoch: 3\n",
      "Train loss: 3.392550268071763\n",
      "Pearson r: 0.874\n",
      "Validation loss: 0.36107248067855835\n",
      "Best Pearson r: 0.874\n",
      "\n",
      "Epoch: 4\n",
      "Train loss: 3.1182480289580976\n",
      "Pearson r: 0.895\n",
      "Validation loss: 0.29299312829971313\n",
      "Best Pearson r: 0.895\n",
      "\n",
      "Epoch: 5\n",
      "Train loss: 2.6080402275349233\n",
      "Pearson r: 0.896\n",
      "Validation loss: 0.29282188415527344\n",
      "Best Pearson r: 0.896\n",
      "\n",
      "Epoch: 6\n",
      "Train loss: 2.2756569366505803\n",
      "Pearson r: 0.889\n",
      "Validation loss: 0.30990391969680786\n",
      "Best Pearson r: 0.896\n",
      "\n",
      "Epoch: 7\n",
      "Train loss: 2.0184028833470444\n",
      "Pearson r: 0.885\n",
      "Validation loss: 0.3181782066822052\n",
      "\n",
      "----Pearson r: 0.896----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kfold_results = pd.DataFrame()\n",
    "\n",
    "set_all_seeds(seed)\n",
    "\n",
    "data_module = KFoldDataModule(\n",
    "    task=task,\n",
    "    checkpoint=checkpoint,\n",
    "    batch_size=16,\n",
    "    feature_to_tokenise=feature_to_tokenise,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "data = data_module.get_data(file=filename)\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kfold.split(data)):\n",
    "    print('Fold:', fold)\n",
    "    \n",
    "    train_loader = data_module.kfold_dataloader(\n",
    "        file=filename, idx=train_idx\n",
    "    )\n",
    "    dev_loader = data_module.kfold_dataloader(\n",
    "        file=filename, idx=test_idx\n",
    "    )\n",
    "\n",
    "    for anno_diff in anno_diff_range:\n",
    "        trainer = KFoldTrainer(\n",
    "            task=task,\n",
    "            checkpoint=checkpoint,\n",
    "            lr=1e-5,\n",
    "            n_epochs=10,\n",
    "            train_loader=train_loader,\n",
    "            dev_loader=dev_loader,\n",
    "            dev_label_gpt=filename,\n",
    "            dev_label_crowd=None,\n",
    "            device_id=0,\n",
    "            anno_diff=anno_diff,\n",
    "            mode=0 # -1: crowd, 1: gpt, 0: crowd-gpt\n",
    "        )\n",
    "    \n",
    "        val_pearson_r = trainer.fit(dev_alpha=False)\n",
    "    \n",
    "        # save as seed in index and anno_diff in columns\n",
    "        print(f'\\n----Pearson r: {val_pearson_r}----\\n')\n",
    "        kfold_results.loc[fold, anno_diff] = val_pearson_r\n",
    "\n",
    "    # # Saving in each fold to be cautious\n",
    "    kfold_results.to_csv('./v1-kfold_results_anno_diff.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b7167c-cad7-4ce2-ae64-6dd8cba1a2b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
