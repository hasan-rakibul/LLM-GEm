{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94915d97-0f63-4805-b4a3-66e94b3c5d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir(\"/g/data/jr19/rh2942/text-empathy/\")\n",
    "from utils.utils import plot, set_all_seeds\n",
    "from utils.common import DataModule, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80e65bb5-f377-4664-8720-b18276ee77b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 'roberta-base'\n",
    "task = ['empathy', 'wrong_empathy']\n",
    "# feature_to_tokenise=['demographic_essay', 'article']\n",
    "# feature_to_tokenise=['demographic', 'essay']\n",
    "feature_to_tokenise=['demographic_essay']\n",
    "\n",
    "################# COMBINED TRAIN FILE ##############\n",
    "# train_file = './data/WS22-WS23-sep-from-aug-train-gpt.tsv' # w/o augmentation\n",
    "train_file = './data/WS22-WS23-augmented-train-gpt.tsv'\n",
    "\n",
    "################# WASSA 2022 ####################\n",
    "# dev_label_crowd = './data/WASSA22/goldstandard_dev_2022.tsv'\n",
    "# dev_file = './data/WS22-dev-gpt.tsv'\n",
    "# dev_label_gpt = './data/WS22-dev-gpt.tsv'\n",
    "\n",
    "################# WASSA 2023 ####################\n",
    "dev_label_crowd = './data/WASSA23/goldstandard_dev.tsv'\n",
    "dev_file = './data/WS23-dev-gpt.tsv'\n",
    "dev_label_gpt = './data/WS23-dev-gpt.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bc2b25-eb23-4a14-b737-3b8934ec164e",
   "metadata": {},
   "source": [
    "# At different seed and alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfd3e8b8-6462-4afb-8f0e-c6991ae24a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_range = [0, 42, 100, 999, 1234]\n",
    "anno_diff_range = np.arange(0, 6.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c6a897-b22b-4438-9fd2-2b03d48e9dd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_results = pd.DataFrame()\n",
    "\n",
    "for seed in seed_range:\n",
    "\n",
    "    set_all_seeds(seed)\n",
    "    \n",
    "    data_module = DataModule(\n",
    "        task=task,\n",
    "        checkpoint=checkpoint,\n",
    "        batch_size=16,\n",
    "        feature_to_tokenise=feature_to_tokenise,\n",
    "        seed=seed\n",
    "    )\n",
    "    \n",
    "    train_loader = data_module.dataloader(file=train_file, send_label=True, shuffle=True)\n",
    "    dev_loader = data_module.dataloader(file=dev_file, send_label=False, shuffle=False)\n",
    "    # test_loader = data_module.dataloader(file=test_file, send_label=False, shuffle=False)\n",
    "\n",
    "    for anno_diff in anno_diff_range:\n",
    "        trainer = Trainer(\n",
    "            task=task,\n",
    "            checkpoint=checkpoint,\n",
    "            lr=1e-5,\n",
    "            n_epochs=10,\n",
    "            train_loader=train_loader,\n",
    "            dev_loader=dev_loader,\n",
    "            dev_label_gpt=dev_label_gpt,\n",
    "            dev_label_crowd=dev_label_crowd,\n",
    "            device_id=0,\n",
    "            anno_diff=anno_diff,\n",
    "            mode=0 # -1: crowd, 1: gpt, 0: crowd-gpt\n",
    "        )\n",
    "\n",
    "        save_as_loss = './ws22ckp/loss-llm-roberta-seed-' + str(seed) + '-anno_diff-' + str(anno_diff) + '.pth'\n",
    "        save_as_pearson = './ws22ckp/pearson-llm-roberta-seed-' + str(seed) + '-anno_diff-' + str(anno_diff) + '.pth'\n",
    "        \n",
    "        val_pearson_r = trainer.fit(save_as_loss, save_as_pearson)\n",
    "\n",
    "        # save as seed in index and anno_diff in columns\n",
    "        print(f'\\n----Seed {seed}, anno_diff {anno_diff}: {val_pearson_r}----\\n')\n",
    "        val_results.loc[seed, anno_diff] = val_pearson_r\n",
    "\n",
    "    # Saving in each seed to be cautious\n",
    "    val_results.to_csv('ws22-val_results_diff_seed_anno_diff.tsv', sep='\\t')\n",
    "\n",
    "# Saving at the end\n",
    "val_results.to_csv('ws22-val_results_diff_seed_anno_diff.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf508d5-296a-46bd-aa45-de900c52887d",
   "metadata": {},
   "source": [
    "# For a fixed setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc69ec6b-9bda-44f5-90b4-d02754f65d41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5268 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/208 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 8.044336840961918\n",
      "Pearson r: 0.225\n",
      "Validation loss: 2.8000993728637695\n",
      "Best dev set Pearson r: 0.225\n",
      "\n",
      "Epoch: 2\n",
      "Train loss: 3.197762204661514\n",
      "Pearson r: 0.273\n",
      "Validation loss: 2.6078591346740723\n",
      "Best dev set Pearson r: 0.273\n",
      "\n",
      "Epoch: 3\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "anno_diff = 6.0\n",
    "\n",
    "set_all_seeds(seed)\n",
    "\n",
    "data_module = DataModule(\n",
    "    task=task,\n",
    "    checkpoint=checkpoint,\n",
    "    batch_size=16,\n",
    "    feature_to_tokenise=feature_to_tokenise,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "train_loader = data_module.dataloader(file=train_file, send_label=True, shuffle=True)\n",
    "dev_loader = data_module.dataloader(file=dev_file, send_label=False, shuffle=False)\n",
    "\n",
    "trainer = Trainer(\n",
    "    task=task,\n",
    "    checkpoint=checkpoint,\n",
    "    lr=1e-5,\n",
    "    n_epochs=10,\n",
    "    train_loader=train_loader,\n",
    "    dev_loader=dev_loader,\n",
    "    dev_label_gpt=dev_label_gpt,\n",
    "    dev_label_crowd=dev_label_crowd,\n",
    "    device_id=0,\n",
    "    anno_diff=anno_diff,\n",
    "    mode=-1 # -1: crowd, 1: gpt, 0: crowd-gpt\n",
    ")\n",
    "\n",
    "trainer.fit(save_as_loss=None, save_as_pearson=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab15c9c9-d937-4f8a-825f-7ef384dad0f3",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc31fe9f-6869-4555-9f08-cb3b2760c545",
   "metadata": {},
   "source": [
    "## WS 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf178ba5-a3a9-4a8c-ace3-3c7df6e106d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "anno_diff = 5.5\n",
    "\n",
    "test_file = './data/PREPROCESSED-WS23-test.tsv'\n",
    "load_model = './ws23ckp/pearson-llm-roberta-seed-' + str(seed) + '-anno_diff-' + str(anno_diff) + '.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388886bc-71f5-44fc-a14d-1a78bd823c3f",
   "metadata": {},
   "source": [
    "## WS 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a008197e-4303-45c5-9b78-ee214f88ccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "anno_diff = 2.0\n",
    "\n",
    "test_file = './data/PREPROCESSED-WS22-test.tsv'\n",
    "load_model = './ws22ckp/pearson-llm-roberta-seed-' + str(seed) + '-anno_diff-' + str(anno_diff) + '.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "87a648e9-cd2f-4945-814a-798332b9401d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with ./data/PREPROCESSED-WS22-test.tsv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/525 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "set_all_seeds(seed)\n",
    "\n",
    "data_module = DataModule(\n",
    "    task=task,\n",
    "    checkpoint=checkpoint,\n",
    "    batch_size=16,\n",
    "    feature_to_tokenise=feature_to_tokenise,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "print('Working with', test_file)\n",
    "test_loader = data_module.dataloader(file=test_file, send_label=False, shuffle=False)\n",
    "\n",
    "trainer = Trainer(\n",
    "    task=task,\n",
    "    checkpoint=checkpoint,\n",
    "    lr=1e-5,\n",
    "    n_epochs=10,\n",
    "    train_loader=None,\n",
    "    dev_loader=None,\n",
    "    dev_label_gpt=None,\n",
    "    dev_label_crowd=None,\n",
    "    device_id=0,\n",
    "    anno_diff=anno_diff,\n",
    "    mode=0 # -1: crowd, 1: gpt, 0: crowd-gpt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "78d5d6d3-b64d-4ffa-80bb-e20306380e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with ./ws22ckp/pearson-llm-roberta-seed-0-anno_diff-2.0.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emp</th>\n",
       "      <th>dis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.462105</td>\n",
       "      <td>5.462105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.194427</td>\n",
       "      <td>4.194427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.507026</td>\n",
       "      <td>3.507026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.420381</td>\n",
       "      <td>4.420381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.127812</td>\n",
       "      <td>3.127812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>1.839970</td>\n",
       "      <td>1.839970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>3.565697</td>\n",
       "      <td>3.565697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>5.970722</td>\n",
       "      <td>5.970722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>5.677538</td>\n",
       "      <td>5.677538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>4.054059</td>\n",
       "      <td>4.054059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>525 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          emp       dis\n",
       "0    5.462105  5.462105\n",
       "1    4.194427  4.194427\n",
       "2    3.507026  3.507026\n",
       "3    4.420381  4.420381\n",
       "4    3.127812  3.127812\n",
       "..        ...       ...\n",
       "520  1.839970  1.839970\n",
       "521  3.565697  3.565697\n",
       "522  5.970722  5.970722\n",
       "523  5.677538  5.677538\n",
       "524  4.054059  4.054059\n",
       "\n",
       "[525 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Working with', load_model)\n",
    "pred = trainer.evaluate(dataloader=test_loader, load_model=load_model)\n",
    "pred_df = pd.DataFrame({'emp': pred, 'dis': pred}) # we're not predicting distress, just aligning with submission system\n",
    "pred_df.to_csv('./tmp/predictions_EMP.tsv', sep='\\t', index=None, header=None)\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "18e546af-dec1-4e18-b607-9f0c595a0b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/g/data/jr19/rh2942/text-empathy/tmp\n",
      "  adding: predictions_EMP.tsv (deflated 66%)\n"
     ]
    }
   ],
   "source": [
    "%cd tmp\n",
    "!zip predictions.zip predictions_EMP.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca399b24-5cb5-4893-afd6-5ce7cd9ceda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/g/data/jr19/rh2942/text-empathy\n"
     ]
    }
   ],
   "source": [
    "!rm predictions_EMP.tsv predictions.zip\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cb44bd-cdd4-453e-9ffd-9c91a88777f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
